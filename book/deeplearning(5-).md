5. 机器学习基础
    1. 学习算法

        学习的定义：对某类任务T和性能度量P，一个计算机程序被认为可以从经验E中学习是指：通过经验E的改进后，它在任务T上由性能度量P衡量的性能有所提升。

        - 任务T
            样本是指我们从某些希望机器学习系统处理的对象或事件中收集到的已经量化的特征的集合。

            常见任务：

            - 分类

                计算机需要指定某些输入属于k类中的哪一类。例如对象识别。

            - 输入缺失分类

                在输入的度量无法全部保证时，学习算法需要学习一组不同的函数，分别对应不同的子集。例如医学疾病监测。

            - 回归

                对给定的输入输出预测值。例如房价预测。

            - 转录

                非结构数据转为文本。例如OCR和语音识别。

            - 机器翻译

                将语言的符号序列转为另一种语言的符号序列。

            - 结构化输出

                将某数据结构映射到输出相关的元素。例如语法分析。

            - 异常检测

                在一组数据中进行筛选，找出不正常或非典型的个体。例如欺诈检测。

            - 合成和采样

                生成一些和训练样本相似的新样本。如画画或作诗。

            - 缺失值填补

                给定一个新样本，补足其中缺失的元素。

            - 去噪

                输入是干净样本的损坏样本，要求预测干净的样本。

            - 密度估计或概率质量函数估计

                通过学习观察到的数据结构对密度估计。

        - 性能度量 P
            
            通过在测试集上进行对准确率和错误率进行评估

        - 经验 E

            机器学习算法分为无监督算法和监督算法。

        - 示例：线性回归

            $$ \hat {y} =w^Tx $$

            向量$x \in \mathbb R^n$作为输入，预测标量$\hat y \in \mathbb R$为输出，$w \in \mathbb R^n$是参数的向量。

            w可以看做是一组决定每个特征如何影响预测的权重。

            $X^{(test)}$表示测试集，回归目标为$y^{(test)}$

            度量模型的性能第一种办法是在测试集上的均方误差。

            $$ MSE_{test}= \frac {1}{m} \sum _i(\hat y^{(test)}-y^{(test)})^2_i $$

            这个计算式和求欧几里得距离等价，欧几里得距离如下：
            
            $$ MSE_{test}= \frac {1}{m}||\hat y^{(test)}-y^{(test)})||^2_2 $$

            目标是最小化 $MSE_{train}$ ，因此直接求导数为0。

            $$ \nabla_wMSE_{train}=0 $$
            $$ \Rightarrow \nabla_w\frac 1m||\hat y^{(train)}-y^{(train)}||^2_2=0 $$
            $$ \Rightarrow \frac 1m\nabla_w||\hat X^{(train)}w-y^{(train)}||^2_2=0 $$
            $$ \Rightarrow \nabla_w(X^{(train)}w-y^{(train)})^T(X^{(train)}w-y^{(train)})=0$$
            $$ \Rightarrow \nabla_w(w^TX^{(train)T}X^{(train)}w-2w^TX^{(train)T})y^{(train)}+y^{(train)T}y^{(train)})=0$$
            $$ \Rightarrow 2X^{(train)T}X^{(train)}w-2X^{(train)T}y^{(train)}=0$$
            $$ \Rightarrow w= \frac {X^{(train)T}y^{(train)}}{X^{(train)T}X^{(train)}}$$      

            这个方程称为正规方程，实际上的线性回归还要加上额外的参数偏置b，即：

            $$\hat y = w^Tx+b$$      

    2. 容量、过拟合和欠拟合

        在之前未观测到的输入上表现良好的能力被称为泛化。

        在训练集计算的叫训练误差，机器学习优化是指期望泛化误差（测试误差）的优化问题。

        线性回归采用 $\frac {1}{m^{train}}||X^{(train)}w-y^{(train)}||_2^2$ 

        但我们实际期望 $\frac {1}{m^{test}}||X^{(test)}w-y^{(test)}||_2^2$
            
        按统计学理论，训练集和测试集上，默认为独立同分布假设，就是每个数据集中的样本都是互相独立的，并且训练集和测试集是同分布的。所以可以观察到随机训练误差和测试误差的期望是一致的。

        机器学习的算法效果：

            1. 降低训练误差

            2. 缩小训练误差和测试误差的差距

        针对上面两种目标，引入训练过程中的两个挑战，欠拟合和过拟合。

        可以通过挑战模型的容量，可以控制模型是否偏向于欠拟合或过拟合。模型的容量是指拟合各种函数的能力。

        控制模型训练算法的方法是选择假设空间。广义的线性回归的假设空间包括了多项式函数，而非仅仅线性函数，这样就增加了模型的容量。

        例如：

        一次多项式：

        $$\hat y = wx+b$$

        二次多项式：

        $$\hat y = w_1x^2+w_2x+b$$

        虽然输入的是二次函数，但输出还是线性函数，所以可以解，还可以继续增加，如九次多项式如下：

        $$ \hat y=\sum_{i=1}^9w_ix^i+b $$

        容量高的模型可以解决更复杂的任务，但当容量高于任务所需时，容易发生过拟合。

        学习算法可以从哪些函数族中挑选函数，称为模型的表示容量；在实际过程中，不会去挑一个正好匹配的函数，而是去挑可以大大降低训练误差的函数。并且有时由于算法的不完美，还可能造成学习算法的有效容量可能小于模型族的表示容量。

        提高模型的泛化能力就是奥卡姆剃刀原则，在同样能够解释观察现象的假设中，挑选最简单的那一个。

        统计学习理论提高了量化模型容量的方法叫VC维度。

        对于非参数模型而言，更多的数据会得到更好的泛化性能。

        1. 没有免费的午餐

            机器学习的没有免费的午餐定理表明：在所有可能的数据生成分布上平均之后，每一个分类算法在未事先观测的点上都有相同的错误率。也就是说没有一种机器学习算法总比其他的好。

        2. 正则化

            可以加入权重衰减来修改线性回归的训练标准。带权重衰减的线性回归最小化训练集上的均方误差和正则项的和J(w),其偏好于L2范数较小的权重。如下：

            $$J(w)=MSE_{(train)}+\lambda w^Tw$$

            其中$\lambda$是提前设置好的值，越大，越偏好范数越小的权重。最小化J(w)可以看做拟合训练数据和偏好小权重范数之间的权衡，这样会使得解决方案的斜率较小，或者将权重放到较少的特征少，可以提高泛化能力。

            正则化是指修改学习算法，使其降低泛化误差而非训练误差。

        3. 超参数和验证集

            预先设置的参数，用来控制算法的行为，例如正则化 $\lambda$

            通常将难以优化的，或不适合在训练集上学习的都设置为超参数；如果在训练集上训练这些超参数，容易导致过拟合。

            用来挑选超参的数据子集被称为验证集。通常80%用来训练，20%用来验证。

            - 交叉验证

                数据过小会导致测试集的误差太小，区分不出算法的优势。可以使用k-折交叉验证算法。

                将数据分为k份来训练，同时将记录每一个误差，求平均。
            

        4. 估计、偏差和方差

            - 点估计

            用一些独立的点来估计超参用。其中将输入和目标变量之间关系的估计称为函数估计。

            - 方差和标准差

            设X为服从分布F的随机变量， 如果E[X]是随机变数X的期望值（平均数μ=E[X]）随机变量X或者分布F的方差为：

            $$Var(X)=E[(X-\mu)^2]$$

            连续变量的方差为：

            $$Var(X)=\sigma^2=\int (x-\mu)^2f(x)dx=\int x^2f(x)dx-\mu^2$$

            $\mu$是期望值，$\mu=\int xf(x)dx$

            离散变量的方差为：

            $$Var(X)=\sum ^m_{i=1}p_i(x_i-\mu)^2=\sum ^m_{i=1}(p_ix_i^2)-\mu^2$$

            $\mu$是期望值，$\mu=\sum ^m_{i=1}p_ix_i$

            方差的平方根称为标准差

            均值的标准差记为：

            $$SE(\hat \mu_m)=\sqrt {Var[\frac 1m\sum ^m_{i=1}x_i]}=\frac \sigma{\sqrt m}$$

            以均值 $\hat \mu_m$ 为中心的 95% 的置信空间为：

            $$(\hat \mu_m-1.96SE(\hat \mu_m),\hat \mu_m+1.96SE(\hat \mu_m))$$

            在机器学习中，常说的算法A比算法B好，是指算法A的误差的95%的置信区间的上界小于算法B的误差的95%置信区间的下界。

            在伯努利分布中，估计 $\hat \theta_m=\frac 1m\sum ^m_{x=1} x_i$ 的方差：

            $$Var(\hat\theta_m)=Var(\frac 1m\sum ^m_{x=1} x_i)$$
            $$=\frac 1{m^2}\sum ^m_{x=1} Var(x_i)$$
            $$=\frac 1{m^2}\sum ^m_{x=1}\theta(1-\theta)$$
            $$=\frac 1{m^2}m\theta(1-\theta)$$
            $$=\frac 1{m}\theta(1-\theta)$$

            可以看出方差下降的速度是数据集的样本 m 的函数。

            - 偏差

            估计的偏差定义为：

            $$bias(\hat \theta_m)=\mathbb E(\hat \theta_m)-\theta$$

            $\mathbb E(\hat \theta_m)$是期望值，$\theta$表示真实值。

            如果$bias(\hat \theta_m)=0$,那么估计量$\hat \theta_m$被称为无偏，这意味着$\mathbb E(\hat \theta_m)=0$;如果$\lim _{m\rightarrow\infty } bias(\hat \theta_m)=0$, 估计量$\hat \theta_m$被称为渐进无偏。


            示例 1：伯努利分布，考虑 {$x_1,...,x_m$}:

            $$p(x_i;\theta)=\theta^{x_i}(1-\theta)^{(1-x_i)}=\begin{cases}\theta, \ if\ x=1\\ 1-\theta, \ if\ x=0\end{cases}$$

            $\theta$的常用估计量是训练样本的均值：

            $$\hat \theta_m=\frac {1}{m}\sum _{i=1}^mX_i$$

            下面来判断这个是否有偏：

            $$
            \begin{aligned}
            bias(\hat \theta_m) &= \mathbb E|\hat \theta_m|-\theta \\\\
            &=\mathbb E[\frac {1}{m}\sum _{i=1}^mX_i]-\theta \\\\
            &=\frac {1}{m}\sum _{i=1}^m\mathbb E[x_i]-\theta\\\\
            &=\frac {1}{m}\sum _{i=1}^m\sum _{x_i=0}^1(x_i\theta^{x_i}(1-\theta)^{(1-x_i)})-\theta \\\\
            &=\frac {1}{m}\sum _{i=1}^m(\theta)-\theta \\\\
            &=\theta - \theta=0
            \end{aligned} 
            $$
            
            附期望值计算公式：

            $$\mathbb E[X]=\sum _ix_ip_i$$

            所以骰子的期望值为：

            $$\mathbb E[x]=1*\frac 16+2*\frac 16+3*\frac 16+4*\frac 16+5*\frac 16+6*\frac 16=3.5$$

            示例 2：均值的高斯分布估计

            $$p(x_1;\mu,\sigma^2)=\frac 1{\sigma\sqrt{2\pi}}e^{-\frac {(x_i-\mu)^2}{2\sigma^2}}$$

            高斯分布的期望值推导：

            1. 对偏差的期望值

                $$\mathbb E(X)=\int ^{\infty }_{-\infty }x\frac 1{\sigma\sqrt{2\pi}}exp\{-\frac {(x-\mu)^2}{2\sigma^2} \}dx$$

                令$y=x-\mu$

                $$\mathbb E(X)=\int ^{\infty }_{-\infty }(y+\mu)\frac 1{\sigma\sqrt{2\pi}}exp\{-\frac {y^2}{2\sigma^2} \}dy$$
                $$=\int ^{\infty }_{-\infty }y\frac 1{\sigma\sqrt{2\pi}}exp\{-\frac {y^2}{2\sigma^2} \}dy+\int ^{\infty }_{-\infty }\mu\frac 1{\sigma\sqrt{2\pi}}exp\{-\frac {y^2}{2\sigma^2} \}dy$$

                第一部分用$I_1$表示

                $$I_1=\int ^{\infty }_{-\infty }x\frac 1{\sigma\sqrt{2\pi}}exp\{-\frac {x^2}{2\sigma^2} \}dx$$

                显然这个积分的函数是对称的是奇函数f(x)=−f(−x))，所以对称区间的积分为0，即$I_1=0$。

                所以：

                $$\mathbb E(X)=\int ^{\infty }_{-\infty }\mu\frac 1{\sigma\sqrt{2\pi}}exp\{-\frac {x^2}{2\sigma^2} \}dx$$
                $$=\mu\int ^{\infty }_{-\infty }\frac 1{\sigma\sqrt{2\pi}}exp\{-\frac {x^2}{2\sigma^2} \}dx$$
                $$=\mu\frac 1{\sigma\sqrt{2\pi}}\int ^{\infty }_{-\infty }exp\{-\frac {x^2}{2\sigma^2} \}dx$$
                $$=\mu\frac 1{\sigma\sqrt{2\pi}}\int ^{\infty }_{-\infty }exp\{-\frac {1}{2\sigma^2}x^2 \}dx$$
                $$=\mu\frac 1{\sigma\sqrt{2\pi}}\frac {\sqrt \pi}{\sqrt {\frac 1{2\sigma^2}}}$$
                $$=\mu\frac 1{\sigma\sqrt{2\pi}}\sqrt \pi\sqrt {2 \sigma^2}$$                
                $$=\mu$$

            高斯的均值参数常用估计量称为样本均值：

            $$\hat \mu=\frac 1m\sum _{(i=1)^m}x_i$$

            看是否有偏，计算如下：

            $$\begin{aligned}
            bias(\hat \mu_m)&=\mathbb E|\hat \mu_m|-\mu \\\\
            &=\mathbb E[\frac 1m\sum _{i=1}^mx_i]-\mu \\\\
            &=(\frac 1m\sum _{i=1}^m\mathbb E[x_i])-\mu \\\\
            &=(\frac 1m\sum _{i=1}^m\mu)-u \\\\
            &=\mu-\mu=0
            \end{aligned}$$

            示例 3：高斯分布方差估计
            
            1. 对方差的期望值

                $$V(X)=\int ^{\infty }_{-\infty }(x-\mu)^2\frac 1{\sigma\sqrt{2\pi}}exp\{-\frac{(x-\mu)^2}{2\sigma^2}\}dx$$
                $$=\int ^{\infty }_{-\infty }x^2\frac 1{\sigma\sqrt{2\pi}}exp\{-\frac{x^2}{2\sigma^2}\}dx$$
                $$=\sigma\sqrt 2\int ^{\infty }_{-\infty }(\sigma\sqrt 2x)^2\frac 1{\sigma\sqrt{2\pi}}exp\{-\frac{(\sigma\sqrt 2x)^2}{2\sigma^2}\}dx$$
                $$=\sigma^2\frac 4{\sqrt \pi}\int ^{\infty }_{-\infty }x^2e^{-x^2}dx$$

                另 $t=x^2$， 则 $dt=2xdx=2\sqrt tdx$ ，则$dx=(2\sqrt t)^{-t}dt$ 代入上式：

                $$V(X)=\sigma^2\frac 4{\sqrt \pi}\int ^{\infty }_0(\sqrt t)^2(2\sqrt t)^{-1}e^{-t}dt$$
                $$=\sigma^2\frac 4{\sqrt \pi}\frac 12\int ^{\infty }_0t^{\frac 32-1}e^{-t}dt$$
                $$=\sigma^2\frac 4{\sqrt \pi}\frac 12\Gamma(\frac 32)=\sigma^2\frac 4{\sqrt \pi}\frac 12\frac {\sqrt \pi}2=\sigma^2$$

            来比较高斯分布参数$\sigma^2$的两个不同估计

            第一个方差为样本方差，如下：

            $$\hat \sigma_m^2=\frac 1m\sum(x_i-\hat \mu_m)^2$$ 

            $\hat \mu_m$为样本均值

            看是否有偏，计算如下：

            $$\begin{aligned}
            bias(\hat \sigma_m^2)&=\mathbb E[\hat\sigma_m^2]-\sigma^2 \\\\
            &=\mathbb E[\frac 1m\sum _{i=1}^m(x_i-\hat\mu_m)^2]-\sigma^2 \\\\
            &=\frac {m-1}{m}\sigma^2-\sigma^2\\\\
            &=-\frac 1m\sigma^2
            \end{aligned}$$

            所以是有偏估计。

            无偏样本方差估计：

            $$\overline \sigma^2_m=\frac 1{m-1}\sum ^m_{i=1}(x_i-\hat \mu_m)^2$$

            看看是否有偏，计算如下：

            $$\mathbb E[\overline \sigma^2_m]=\mathbb E[\frac 1{(m-1)}\sum ^m_{i=1}(x_i-\hat \mu_m)^2]$$
            $$=\frac m{m-1}\mathbb E[\hat \sigma_m^2]$$
            $$=\frac m{m-1}(\frac {m-1}m\sigma^2)$$
            $$=\sigma^2$$

            所以是无偏估计。

            - 权衡偏差和方差的最小化均方误差

            判断偏差和方差之间的最优，采用的交叉验证，或也可以采用均方误差(MSE)来衡量：

            $$MSE=\mathbb E[(\hat \theta_m-\theta)^2]$$
            $$=Bias(\hat \theta_m)^2+Var(\hat \theta_m)$$

            当用MSE来度量泛化误差时，增加函数容量，会增加方差，降低偏差。

            - 一致性

            一致性保证了估计量的偏差随数据样本的增加而减少。

            - 最大似然估计

            衡量模型函数的估计，最常用的是最大似然估计。就是利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值。

            最大似然估计中采样需满足一个重要的假设，就是所有的采样都是独立同分布的。

            参数就是概率的意思，$p(x|\theta)$ 是指概率为 $\theta$ 的分布。例如投掷硬币，正面的分布表示为 $p(x|\theta)=0.5$。
        
            参数估计有两种方法，一种是矩方法，一种是最大似然估计。统计均值就是矩估计，基于大数定理；不过统计学基本都是采用最大似然的方法。

            有一组样本，$x_1,x_2,x_3,...,x_n$ ，其每一个变量都对应一个似然函数：

            $$p(x_1|\theta),p(x_2|\theta),p(x_3|\theta),...,p(x_n|\theta)$$

            将这些函数全部相乘：

            $$L(\theta)=\prod ^n_{i=1}p(x_i|\theta)$$

            我们只要找到令 $L(\theta)$ 最大的 $\theta$ 值，就是我们想要的参数值。

            例子：一个袋子装有白球和红球，抽取10次，每次抽取后都放回，假设抽到7次白球和3个红球，求袋子中白球的比例。

            直观上应该是70%，以下用最大似然估计来解。

            定义从袋子中抽取白球和红球的概率如下：

            $$f(x_1,x_2|\theta)=f(x_1|\theta)*f(x_2|\theta)$$

            $x_1$为第一次采样，$x_2$为第二层采样，f为模型，$\theta$为模型参数

            其中 $\theta$ 未知，定义似然 L, $\prod$ 表示乘积运算：

            $$L(\theta|x_1,x_2)=f(x_1,x_2|\theta)=\prod ^2_{i=1}f(x_i|\theta)$$ 

            两边取对数ln，取对数是为了将右边的乘号变加号，方便后面求导。

            $$lnL(\theta|x_1,x_2)=ln(\sum ^2_{i=1}f(x_i|\theta))=\sum ^2_{i=1}lnf(xi|\theta)$$

            两边取对数后，左边称为对数似然。

            平均对数似然：

            $$\hat e=\frac 12lnL(\theta|x_1,x_2)$$

            最大似然估计，就是找到一个合适的$\theta$，使平均对数似然最大。

            $$\hat \theta=argmax\hat e(\theta|x_1,x_2)$$

            定义M为模型（也就是f），白球的概率为$\theta$，红球的概率为($1-\theta$)，因此10次抽到白球7次的概率为：

            $$P(x_1,x_2,...,x_{10}|M)=P(x_1|M)*P(x_2|M)...*P(x_{10}|M)=\theta^7(1-\theta)^3$$

            转换为平均似然：

            $$\hat e=\frac 1{10}P(x_1,x_2,...,x_{10}|M)=\frac 1{10}ln(\theta^7(1-\theta)^3)$$

            为了求最大的平均似然，直接对上面求导，导数为0时为最大值。

            $$\hat e'(\theta)=7\theta^6(1-\theta)^3-3\theta^7(1-\theta)^2=0$$
            $$\Rightarrow \theta=0.7 $$

            得：当抽取白球的概率为0.7时，最可能产生10次抽取白球7次的事件。

            最优化 $\theta$ 在最大似然估计或最小化KL散度是相同的，但目标函数值不一样。在机器学习中最大化似然变成最小化负对数似然，或等价的最小化交叉熵。

            - 条件对数似然和均方误差

            最大似然估计很容易扩展到条件概率。

            $$\hat \theta = argmaxP(Y|X;\theta)$$

            如果样本同分布，可以分解为：

            $$\hat \theta = argmax\sum ^m_{i=1}logP(y_i|x_i;\theta)$$

            实例：线性回归作为最大似然

            线性回归采用最小均方误差来计算。现在期望得到条件概率，假定方差为固定的 $\sigma^2$。

            条件对数似然如下：

            $$\hat \theta=\sum ^m_{i=1}logp(y_i|x_i;\theta)$$
            $$=-mlog\sigma-\frac m2log(2\pi)-\sum ^m_{i=1}\frac {||\hat y_i-\hat y_i||^2}{2\sigma^2}$$

            对比均方误差为：

            $$MSE_{train}=\frac 1m\sum ^m_{i=1}||\hat y_i-y_i||^2$$

            可以看出，最大化w的对数似然和最小化均方误差可以得到相同的参数估计w。但这两种方法有不同值，所以最大似然有不同的性质。

            - 最大似然估计的性质

            最大似然被证明当样本数目趋于无穷大时，就收敛率而言是最好的渐进估计。

            当样本数量较少时，优先考虑最大似然估计；但样本较大时，均方误差和最大似然效果一致。但样本少到发生过拟合时，正则化策略权重衰减可以用在最大似然的有偏版本用于减少方差。

        - 贝叶斯统计

        贝叶斯概率和统计概率相对，它从确定的分布中观测到的频率或者在样本空间中的比例来导出概率。

        古典统计学的概率是基于大量实验的，例如扔硬币猜正反面，多次后，统计结果，得到近似50%的概率。但小概率事件的确定，没有办法做实验，例如发生地震的概率，没有办法通过大量的实现确定参数导致的概率。

        例子，某种特征，得癌症的测出为阳性的几率为90%，而人群中得癌症的几率为1%。问一个人被测出阳性，得癌症的几率是多少？

        中间有个问题是采用的样本分布不均，所以不能直接得出是90%，需要考虑1%的样本分布。

        我们用A表示测试出阳性，B表示得癌症，B'表示未得癌症，根据如上得：

        $$P(A|B)=0.9,P(A|B')=0.1,P(B)=0.01,P(B')=0.99$$

        那么，已知为阳性的情况，得癌症概率P(B,A),这里表示的是联合概率，等于人群中得癌症的概率乘以得癌症时为阳性的概率:

        $$P(B,A)=P(A|B)*P(B)=0.01*0.9=0.009$$

        同理，未得癌症，但检测出来为阳性的概率为：

        $$P(B',A)=P(A|B')*P(B')=0.99*0.1=0.099$$

        这个概率表示了，1000个人，检查出阳性并得癌症的有9个，检查出阳性未的癌症的有99个。所以看出，检测出阳性并不可怕，与直觉不符。

        所有得阳性的概率为：

        $$P(A)=P(B,A)+P(B',A)=0.099+0.009=0.108$$

        继续计算阳性的癌症的概率，直接将样本中的9和99做归一化得到条件概率：

        $$P(B|A)=\frac {0.009}{0.108}=0.083$$

        阳性未得癌症的概率：
        
        $$P(B'|A)=\frac {0.099}{0.108}=0.917$$

        这个条件概率就是贝叶斯统计的后验概率，而P(B)是先验概率。

        知道先验概率，是否为阳性；再根据观察值，来判断癌症的后验概率，这个就是贝叶斯统计。即，后验概率为：

        $$P(B|A)=\frac {P(A|B)*P(B)}{P(A)}=\frac {P(A|B)*P(B)}{P(A|B)*P(B)+P(A|B')*P(B')}$$


        实例：假设一个学校里有60％男生和40%女生。女生穿裤子的人数和穿裙子的人数相等，所有男生穿裤子。一个人在远处随机看到了一个穿裤子的学生。那么这个学生是女生的概率是多少？

        事件A是看到一个穿裤子的学生，事件B是看到女生，要计算的是P(B|A)

        P(B) 是忽略其他因素，看到女生的概率 40%

        P(B') 是是忽略其他因素，看到男生的概率，60%

        P(A|B) 是女生穿裤子的概率 50%

        P(A|B') 是男生穿裤子的概率 100%

        P(A) 是忽略其他因素，学生穿裤子的概率为：
        
        $$P(A)=P(A|B)*P(B)+P(A|B')*P(B')=0.5*0.4+1*0.6=0.8$$

        则计算后验概率，也就是条件概率为：

        $$P(B|A)=\frac {P(A|B)P(B)}{P(A)}=\frac {0.5*0.4}{0.8}=0.25$$

        将上述的A变成样本x，B 变成参数 $\theta$ 于是得到贝叶斯公式：

        $$p(\theta|x)=\frac {p(x|\theta)p(\theta)}{\sum _ip(x|\theta)p(\theta)}$$

        上面由于$B(\theta)$事件的分布是离散的，所以用到了求和，如果是连续的，则采用积分：

        $$p(\theta|x)=\frac {p(x|\theta)p(\theta)}{\int p(x|\theta)p(\theta)d\theta}$$

        其中 $p$ 是参数的概率分布，$p(\theta)$是先验概率，$p(\theta|x)$是后验概率，$p(x|\theta)$是我们观察到的样本分布，也就是似然函数。

        假设有一组数据样本 {$x_1,...,x_m$}，通过贝叶斯规则结合数据似然$p(x_1,...,x_m|\theta)$和先验，可以恢复数据对我们关于$\theta$的信念的影响：

        $$p(\theta|x_1,...,x_m)=\frac{p(x_1,...,x_m|\theta)p(\theta)}{p(x_1,...,x_m)}$$

        先验一般是相对均匀或高熵的高斯分布，观察数据会使后验的熵下降，并集中在参数的几个可能性很高的值。

        相对最大似然估计，贝叶斯估计有两个不同，第一，贝叶斯估计的$\theta$是全概率，例如在观察到 m 个样本后，m+1个样本的预测分布如下：

        $$p(x_{m+1}|x_1,...,x_m)=\int p(x_{m+1}|\theta)p(\theta|x_1,...,x_m)d\theta$$
        
        这样每一个具有正概率的$\theta$有助于下一个样本的预测。其中的贡献由后验密度进行加权。
        
        并且前期的不确定性也可以一直包含下去，这样可以防止过拟合。

        第二个不同是贝叶斯的先验概率能够影响概率密度朝先验的区域偏离。先验是人为主观判断影响概率的来源，这样会导致比较好的泛化性能。

        实例贝叶斯线性回归：









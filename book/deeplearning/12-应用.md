本节将如何使用深度学习来解决不同商业领域的应用。

1. 大规模深度学习

    深度学习的基本思想基于联结主义，一个最关键的因素就是网络规模的巨大提升。

    1. 快速的CPU实现

        现在可以多CPU并行计算，或者针对CPU的某些特性加强。

    1. GPU实现

        NVIDIA的CUDA编程语言提供了神经网络的理想平台，但和CPU很不相同。

    1. 大规模的分布式实现

        数据并行是很容易实现，模型并行也是可行的，每个机器负责模型的一个部分。

        但梯度下降会出现麻烦，不过可以用异步随机梯度下降来解决，即利用锁来处理；新的提出了多机器无锁的梯度下降法，是采用参数服务器管理而非存储到共用的内存中。

    1. 模型压缩

        由于需要部署到移动端或资源有限的环境，减少推断开销的一个关键策略就是模型压缩。基本思想是用一个更小的模型代替原始耗时的模型。

        主要是样本数不够的原因，所以才使用巨大的参数量超过任务的需求。可以先训练一个大的模型，然后通过这个大模型源源不断的参数样本，来训练一个新的更小的模型。

        或者直接在原始训练上训练一个更小的模型，但只是为了复制模型的其它特征。（老师-学生训练）

    1. 动态结构

        加速数据处理的办法是构造一个系统，用动态结构，对于输入的数据，数据处理系统可以动态的决定运行神经网络系统的哪一部分。也称为条件计算。

        在分类器中加速推断中可以使用级联的分类器，先分类为低容量高召回率的，最后一个训练为高精度的。这样可以依次推断，中间任何一层拒绝，就选择抛弃，这样就不需要为每个样本付出完全推断的成本。例如Google的街景地址编号识别，第一步先查找地址编号，第二步再进行转录。

        还可以用类似的选通器，将当前给定的输入使用几个专家网络来计算输出。每个选通器为每个专家输出一个概率或权重，并且最终输出由个个专家输出的加权组合获得。但如果每个选通器只选择单个专家网络，就可以加速推断和训练。

        还有一种动态结构是开关，隐藏单元可以根据情况从不同的单元接收输入。这种动态路由的方法可以理解为注意力机制。但这种机制没有得到大规模应用的验证有效性。

    1. 深度网络的专用硬件实现

        目前有 ASIC 或 FPGA 的实现。

1. 计算机视觉

    包括图像识别，图像标注、图像合成等。

    1. 预处理

        - 有些尺寸固定的模型需要裁剪或缩放调整图像尺寸，有些卷积可接受可变大小的输入，并动态调整池化区域，以保持输出大小恒定。

        - 数据增强通过不同位置的裁剪或其它方式可以将同一输入的不同版本传给模型，有助于减少泛化误差。

        - 对于大型数据集和大规模模型训练时，预处理通常不重要，例如AlexNet系统只有一个预处理，对每一个像素减去训练样本的平均值。

        1. 对比度归一化

            有张图片的张量为 $X \in \mathbb R^{h,w,3}$ 

            $X_{i,j,1}$ 表示第i行第j列红色的强度，$X_{i,j,2}$ 表示第i行第j列绿色的强度，$X_{i,j,1}$ 表示第i行第j列蓝色的强度。则整个图片的对比度为：

            $$\sqrt {\frac {1}{3hw}\sum_{i=1}^h\sum_{j=1}^w\sum_{k=1}^3(X_{i,j,k}-\bar X)^2}$$

            $\bar X$ 是整个图片的平均强度，为：

            $$\bar X={\frac {1}{3hw}\sum_{i=1}^h\sum_{j=1}^w\sum_{k=1}^3X_{i,j,k}}$$

            全局对比度归一化（GCN）定义为：

            $$X'_{i,j,k}=s\frac {X_{i,j,k}-\bar X}{max[\epsilon,\sqrt{\lambda+{\frac {1}{3hw}\sum_{i=1}^h\sum_{j=1}^w\sum_{k=1}^3(X_{i,j,k}-\bar X)^2}}]}$$

            除了全局对比度归一化，还有白化（sphering 或 whitening），将图像进行PCA分解。

            全局对比度归一化不能突出想要突出的图像特征，如边缘和角，所以产生了局部对比归一化，将对比度在每一个小窗上进行，而不是作为一个整体进行。

            [演示代码](./code/12-1.py)

        1. 数据集增强

            对图像进行一些变化，如随机翻转或旋转等。还有加上颜色的随机扰动以及非线性几何变形。

            [演示代码](./code/12-2.py)

1. 语音识别

    语音识别是将一段包含了自然语言发音的声学信号投影到对应说话人的词序列上。



随机算法中蒙特卡罗算法可以在任意固定的计算资源下，得到一个近似解。

1. 采样和蒙特卡罗方法

    1. 为什么需要采样

        当我们需要以较小的代价近似许多项的和或某个积分时，采样是一种很灵活的选择。例如小批量训练；另外当我们想训练一个可以从训练分布采样的模型，抽样就是我们的实际目标。

    1. 蒙特卡罗采样的基础

        当无法精确的计算和或积分时，通常可以使用蒙特卡罗采样来近似它。

        令：

        $$s=\sum_sp(x)f(x)=E_p[f(x)]$$

        或：

        $$s=\int p(x)f(x)dx=E_p[f(x)]$$

        p是一个关于随机变量x的概率分布（求和时）或概率密度函数（求积分时）

        可以从p中抽取n个样本$x_1$,...,$x_n$来近似s并得到一个经验平均值：

        $$\hat s_n=\frac {1}{n}\sum_{i=1}^nf(x_i)$$

        由下可知$\hat s$是无偏的：

        $$\mathbb E[\hat s_n]=\frac1n\sum_{i=1}^n\mathbb E[f(x_i)]=\frac1n\sum_{i=1}^ns=s $$

        加上根据大数定律，如果样本$x_i$是独立同分布的，那么其平均值将收敛为期望值，即：

        $$\lim_{n\to \infty}\hat s_n=s$$

        则：

        只要满足各个单项的方差有界，即当n增大时，$\hat s_n$的方差只要满足 $Var[f(x_i)]<\infty$,那么，方差$Var[\hat s_n]$就会减小收敛到0：

        $$Var[\hat s_n]=\frac1{n^2}\sum_{i=1}^nVar[f(x_i)]=\frac{Var[f(x)]}{n}$$

        结论，蒙特卡罗估计的期望误差计算为：先计算出$f(x_i)$的经验均值和方差，然后将估计的方差除以样本数n，得到$Var[\hat s_n]$的估计。

        根据中心极限定理，$\hat s_n$的分布收敛到以s为均值和以$\frac{Var[f(x)]}{n}$为方差的正态分布，这样就可以利用正态分布的累积函数来估计$\hat s_n$的置信区间。

        上述是依赖于可以从p(x)的分布均匀采样，如果无法从p采样时，一种办法是利用重要采样，一种办法是构建一个收敛到目标分布的估计序列，即马尔科夫链蒙特卡洛方法。


    1. 重要采样

        


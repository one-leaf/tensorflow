随机算法中蒙特卡罗算法可以在任意固定的计算资源下，得到一个近似解。

1. 采样和蒙特卡罗方法

    1. 为什么需要采样

        当我们需要以较小的代价近似许多项的和或某个积分时，采样是一种很灵活的选择。例如小批量训练；另外当我们想训练一个可以从训练分布采样的模型，抽样就是我们的实际目标。

    1. 蒙特卡罗采样的基础

        当无法精确的计算和或积分时，通常可以使用蒙特卡罗采样来近似它。

        蒙特卡罗的思想就是用随机投点法来模拟不规则图形的面积。

        如：在1*1的矩形中，有一个不规则图形，直接计算该图形的面积很困难，那么可以拿N个点，随机抛在矩形内，数一下落入到该不规则图形中的点的个数 count ,那么该不规则图形的面积就可以用 count/N 来近似。

        令：

        $$s=\sum_sp(x)f(x)=E_p[f(x)]$$

        或：

        $$s=\int p(x)f(x)dx=E_p[f(x)]$$

        p是一个关于随机变量x的概率分布（求和时）或概率密度函数（求积分时）

        可以从p中抽取n个样本$x_1$,...,$x_n$来近似s并得到一个经验平均值：

        $$\hat s_n=\frac {1}{n}\sum_{i=1}^nf(x_i)$$

        由下可知$\hat s$是无偏的：

        $$\mathbb E[\hat s_n]=\frac1n\sum_{i=1}^n\mathbb E[f(x_i)]=\frac1n\sum_{i=1}^ns=s $$

        加上根据大数定律，如果样本$x_i$是独立同分布的，那么其平均值将收敛为期望值，即：

        $$\lim_{n\to \infty}\hat s_n=s$$

        则：

        只要满足各个单项的方差有界，即当n增大时，$\hat s_n$的方差只要满足 $Var[f(x_i)]<\infty$,那么，方差$Var[\hat s_n]$就会减小收敛到0：

        $$Var[\hat s_n]=\frac1{n^2}\sum_{i=1}^nVar[f(x_i)]=\frac{Var[f(x)]}{n}$$

        结论，蒙特卡罗估计的期望误差计算为：先计算出$f(x_i)$的经验均值和方差，然后将估计的方差除以样本数n，得到$Var[\hat s_n]$的估计。

        根据中心极限定理，$\hat s_n$的分布收敛到以s为均值和以$\frac{Var[f(x)]}{n}$为方差的正态分布，这样就可以利用正态分布的累积函数来估计$\hat s_n$的置信区间。

        上述是依赖于可以从p(x)的分布均匀采样，如果无法从p采样时，一种办法是利用重要采样，一种办法是构建一个收敛到目标分布的估计序列，即马尔科夫链蒙特卡洛方法。


    1. 重要采样

        相对于直接采样，直接采样就是通过对均匀分布采用，实现对任意分布的采样。
        
        重要采样的主要应用就是用一个新的带权重的采样分布来代替原有的采样分布使得采样更加容易高效。

        蒙特卡罗采样即：

        $$E[\hat s]=\int _xp(x)f(x)dx=\frac {1}{n}\sum_{i=1}^nf(x_i)$$

        正常我们会按照 p(x) 的分布来产生随机数进行采样，但如果p(x) 未知，就无法进行针对 p(x) 进行采样来估计期望值。

        所以，我们引入一个新的已知分布 q(x) ，将原来公式变为：

        $$E[\hat s]=\int _xq(x)(\frac {p(x)}{q(x)}f(x))dx$$

        这样我们就可以针对 q(x) 来对 p(x)/q(x)*f(x) 来进行采样。

        $$E[\hat s_q]=\frac {1}{n} \sum _{i=1,x_i\sim q}^n \frac {p(x_i)}{q(x_i)}f(x_i)$$

        然后，q(x)可以通过计算相差距离或其它评估指标被简单的推导出来。

        如果要保证方差最小，还需要使得q(x)的和或积分为1，即：

        $$q(x)=\frac {p(x)|f(x)|}{Z}$$

        Z为归一化常数。

        问题是高维度下q很难确定。

        对应机器学习的分类器，其中代价函数的大部分代价来自少量的错误分类的样本，这种情况下，通过更频繁的抽取这些困难样本可以减少梯度估计的方差。

    1. 马尔可夫链蒙特卡罗方法

        很多情况下，希望采用蒙特卡罗方法，但又不存在一种简单的方法可以直接从目标分布中精确采样或者一个方差小的重要采样，这时可以采用利用马尔可夫链来进行蒙特卡罗估计。

        最常用的基于能量的模型，即：$p(x)\propto exp(-E(x))$。

        马尔可夫链的核心思想是从某个可取任意值的状态x出发。随着时间的推移，我们随机的反复更新状态x，最终x成为了一个从p(x)中抽出的非常接近一般的样本。定义中，马尔可夫链有一个随机状态x和一个转移分布$T(x^{'}|x)$定义而成。$T(x^{'}|x)$是一个概率分布，定义了给定状态x的情况下随机的转移到$x^{'}$的概率。这样如果并行运行多个马尔可夫链，就可以完成目标$q_t(x)$收敛到$p(x)$。

        无论状态是连续的还是离散的，所有的马尔可夫链方法都包含重复、随机的更新直到最后状态开始从均衡分布中采样。运行马尔可夫链直到它达到均衡分布的过程通常称为马尔可夫链的磨合过程。达到平衡后，可以从均衡分布中抽取一个无限多数量的样本序列，这些样本服从同一分布，但两个连续的样本之间会高度相关，所以一般是每隔n个样本返回一个样本。

        马尔可夫链的问题是计算成本太高，另外无法预知磨合时间需要多长，也无法知道磨合是否已经达到平衡，只能用启发式的方法来检查和判读是否磨合成功。

    1. Gibbs 采样

        
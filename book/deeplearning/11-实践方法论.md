设计流程：

- 确定目标，使用什么样的误差度量

- 尽快建立一个端到端的工作流程，和确定性能度量标准

- 搭建系统，并确定性能瓶颈

- 根据具体观察，调参和增量式改进

1. 性能度量

    针对二元分类器，正确描述系统的性能，通过精度和召回率。精度是模型报告的检测正确的比例，召回率是真实事件被检测到的比例。

    通常用PR曲线，y表示精度，x表示召回率。
    
    如果用一个数来恒定就是 F 分数，其中精度为p，召回率为r，即： 
    
    $$F=\frac {2pr}{p+r}$$

    另外一种报告PR曲线下方的总面积。

    [参考代码](./code/11-1.py)

2. 默认的基准模型

    1. 根据数据结构选择合适的模型。如果输入是固定大小的向量，则使用全连接网络；如果是拓扑结构，如图片，则使用卷积，同时考虑使用Relu或其它分段线性单元；如果输入或输出是序列，则采用LSTM或GRU。

    2. 使用具有衰减的学习率以及动量SGD是一个合理的选择；也可以选择Adam算法。 批标准化对优化有显著影响，特别是针对卷积核具有sigmoid非线性函数的网络。

    3. 除非你的样本数千万以上，否则应该加上一些温和的正则化，包括提前终止和Dropout。如果包含了批标准化，可以省略Dropout，因为批标准化本身就包含了噪声。

    4. 如果任务和另一个被广泛研究的任务相似，可以直接复制之前已经研究的模型和算法。

    5. 除非在半监督的设定下（样本太少），否则无监督学习没有益处。只有在解决无监督问题时，才采用无监督学习。

1. 决定是否收集更多数据

    一般建立一个模型后，新手会尝试很多算法来改进性能。然而，收集更多的数据往往比改进学习算法要有用的多。

    判断是否需要收集更多数据的条件：

    1. 确定训练集上的性能是否可以接受。如果训练集的性能很差，就没有必要收集更多数据，而是修改模型，增加网络的宽度或深度。如果更大的模型，仍然表现不佳，就需要重新开始，收集更干净的数据或收集特征更丰富的数据。

    1. 如果训练集效果可以接收，就去测量测试集，如果测试集可以接受，就结束。如果测试集性能比训练集差很多，就需要收集更多的数据。如果无法收集到更多的数据，就减少网络规模，加入正则化策略等；如果还不行，就必须要收集更多的数据了。

    1. 要收集多少数据，可以绘制泛化误差和训练集规模曲线，来确定。一般增加少量的样本对泛化误差的影响很小，正常都是倍增样本。

    1. 如果收集数据不可行，那么改善泛化误差的唯一办法是改进学习算法，但这个属于研究领域，对应用实践者不合适。

1. 选择超参数

    1. 手动调整超参数
    
        - 目标是最小化受限于运行时间和内存预算的泛化误差

        - 主要目标是调整模型的有效容量以匹配任务的复杂性。

            - 模型的表示容量
            
            - 学习算法最小化模型代价函数的能力

            - 正则化模型

        - 一般通过泛化误差和超参数做图，判断是欠拟合还是过拟合，针对性处理；有些参数是离散的，只能通过减小模型容量来解决。

        - 学习率是最重要的超参数，当学习率适合优化问题时，模型的有效容量最高。学习率过大会不经意增加训练误差，太小不仅慢，还有可能永久停滞。

        - 调整除开学习率的其它参数，要同时监控训练误差和测试误差，以判断模型是过拟合还是欠拟合。
        
            - 如果训练错误率大于测试误差率，只能增加模型容量，如果没有用到正则化，并且优化也正常，就有必要增加更多的网络层或隐藏单元，但这样会增加模型的计算代价。

            - 如果测试集错误率大于训练集错误率，则采用计算测试集错误率和训练集错误率的测试误差来衡量，可以通过正则化超参数达到减少有效模型容量，如：Dropout或权重衰减等。

    1. 自动超参数优化算法

        如果你有经验就手工调参数，如果没有，就可以去找超参数优化算法，原则上可能有这样的算法，但超参数算法往往有自己的超参数，不过相对会容易选择。

    1. 网格搜索

        当有3个或更少的超参数时，最常见的超参数搜索算法就是网格搜索。每个超参数选择对数尺寸下的值（1e-1,1e-2,1e-3,1e-4,...）h或隐藏单元的数目(50,100,200,500,...)去探索，然后将这些超参数笛卡尔乘积得到一组组超参数，然后网格搜索使用这些组超参数去搜索，找出一组验证集误差最小的超参数作为最好的超参数。

        问题是，计算代价随着超参数数量呈指数级增长。

    1. 随机搜索

        首先为每一个参数定义一个边缘分布，如伯努利分布或多项分布，或对数尺度上的均匀分布。
        
        与网络搜索不同，不需要离散化超参数的值，这样搜索速度比较快，同时也可以在更大尺度上进行搜索。

    1. 基于模型的超参数优化

        可以将超参数的优化看做为一个优化问题，决策变量是超参数，优化的代价是模型结果再验证集上的误差，这样可以计算验证集上可导误差函数关于超参数的梯度，然后可以按这个梯度去更新超参数。但问题在于大多数设置中，这个梯度实际不可用，主要在于计算成本和存储成本过高或验证集误差在超参上本质不可导。

        可以尝试对验证集误差进行建模，然后通过优化模型来提出新的超参数猜想。大部分的基于模型的超参数搜索算法，都是使用贝叶斯回归模型来估计每个超参数的验证集误差和该期望的不确定性。

        但这种方法并不成熟可靠，有时效果很好，有时又发生灾难性失误。
    
1. 调试策略

    机器学习系统，很难调试。比如达到了5%的测试误差，无法直接指导这个是期望的结果，还是次优的结果。

    还有一个难点是，大部分机器学习都有自适应的部分，如果部分失效了，但其他部分仍然可以自适应，并获得大致可以接受的性能。

    有如下比较重要的调试检测：

    1. 可视化计算中模型的行为：例如看cnn每层收集到的信息

    2. 可视化最严重的错误：将最严重的错误对应的样本显示出来

    3. 根据训练和测试误差检测软件：

    4. 拟合极小的数据集：如果是欠拟合，可以尝试这样查看是否是模型问题。

    5. 比较反向传播导数和数值导数：针对自己写梯度和求导的时复核用。

    6. 监控激活函数值和梯度的直方图：看激活单元的值，是否处于饱和区域。

1. 实例：多位数字识别

    对于识别门牌号的街景图片任务而言：

    1. 采集数据，街景车收集原始数据，操作员手工提供标签。还有些包括利用其他机器学习进行探测下门牌号测试等。

    2. 选择项目的业务目标，如达到人类水平，98%的准确率，但这样的高水平很难有高的覆盖率，因此目标确定为覆盖率95%。

    3. 建立基准系统，这个项目中采用带整流线性单元的卷积网络，开始用一个简单的基准序列，用n个softmax单元来预测n个不同的字符序列。

    4. 反复细化这些基准，并测试每次变化是否有改进。识别系统的第一个变化受覆盖指标的影响，即输出的序列的概率低于某个值t，即拒绝为输入的 x 进行分类。最初的 p(y|x) 的定义是临时的，简单的将所有的softmax函数的输出乘在一起，这个最后导致发展出合理的对数似然特定输出层和代价函数，使样本拒绝机制更有效。

    5. 此时覆盖仍低于90%，但方法没有明显的理论问题了，因此综合训练集和测试集，以确定问题是欠拟合还是过拟合。结果发现两边的测试结果一样，如果训练集和测试集的误差相似，只有两种可能，第一个是欠拟合，第二是训练数据有问题。因此可视化输出最糟糕的错误，发现图像裁剪的太紧，有些和地址相关的数字被裁剪操作除去了，然后团队简单扩大了裁剪区域的宽度，使其大于地址号码检测系统预测的区域宽度，这种单一改变就将覆盖提升了10%。

    6. 性能提升的最后几个百分点来自调整超参数。主要包括在保持计算代价的同时增加模型的规模，因为之前的训练集和测试集误差相似，所以表明是欠拟合，模型性能不足，当然数据集也有一些问题。

    7. 最后项目是非常成功的。











自编码器是神经网络的一种，能将输入复制到输出。我们不能将自编码器设计成输入和输出完全相等，我们向自编码器中加入一些约束，使其只能近似的复制，并只能复制与训练数据相似的输入。这些约束强制模型考虑输入数据的哪些部分需要被优先复制，从而学习到数据的有用特性。

传统的自编码器用于降维或特征学习，近来，自编码器与潜变量模型理论的联系将自编码器带到了生成式建模的前沿。

自编码器可以被看做是前馈网络的一个特例，可以使用小批量梯度下降法进行训练。与前馈网络不同的是，自编码器还可以用再循环训练，不过这种算法很少用于机器学习应用。




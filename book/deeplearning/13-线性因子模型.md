许多前沿研究都涉及到构建输入的概率模型$p_{model}(x)$。原则上，给定任何其它变量的情况下，这样的模型可以使用概率推断来预测其环境中的任何变量。

许多这样的模型还具有潜变量 h ，其中 $p_{model}(x)=\mathbb E_hP_{model}(x|h)$ 。 这些潜变量提供了表示数据的另一种方式。

本节主要讲基于潜变量的最简单的概率模型：线性因子模型。这些模型用来作为混合模型的组成模块或更大的深度概率模型。

线性因子模型描述如下的数据生成过程：

首先，从一个分布中抽取解释性因子 h：

$$h\sim p(h)$$

其中 $p(h)$ 是一个因子分布，满足 $p(h)=\prod_ip(h_i)$，所以易于采样，接下来，在给定因子的情况下，我们对实值的可观察变量进行采样：

$$x=Wh+b+noise$$

其中噪声$noise$通常是对角化（即在维度上是独立的）且服从高斯分布。

1. 概率PCA和因子分析

    在因子分析中，潜变量的先验是一个方差为单位矩阵的高斯分布：

    $$h\sim \mathcal N(h;0,I)$$

    同时假定在给定$h$的条件下，观察值$x_i$是条件独立的。
    
    这样可以假设噪声是从对角协方差的高斯分布中抽取的，协方差矩阵为：$\psi=diag(\sigma^2)$，其中$\sigma^2=[\sigma_1^2,\sigma_2^2,...,\sigma_n^2]^T$ 表示一个向量，每个元素表示一个变量的方差。

    因此：潜变量的作用是捕获不同观测变量$x_i$之间的依赖关系，可以看出x服从多维正态分布，并满足：

    $$x \sim \mathcal N(x;b,WW^T+\psi)$$

    或等价于：

    $$x=Wh+b+\sigma z$$

    其中 $z \sim \mathcal N(z;0,I)$ 是高斯噪声，之后可以用迭代算法来估计参数 W 和 $\sigma^2$。

    这个概率PCA模型利用了：除了一些微小残余的重构误差（$\sigma^2$）,数据中的大多数变化可以由潜变量$h$描述。当 $\sigma \rightarrow 0$ 时，概率PCA将变为PCA即，h的条件期望等于将x-b投影到W的d列所生成的空间上，同时会导致密度函数在W的空间周围非常尖锐，会导致模型不在一个超平面附近聚集的数据分配非常低的概率。

    [实例代码](./code/13-1.py)

1. 独立成分分析

    独立成分分析(ICA)是一种建模线性因子的方法，旨在将观察到的信号分离成许多潜在信号，这些潜在信号通过缩放和叠加可以恢复成观察数据。这些信号是完全独立的，不仅仅是彼此不相关。

    先人工指定潜在因子$h$的先验$p(h)$，然后模型确定性生成 $x=Wh$，这样可以通过非线性变化来确定 $p(x)$，最后通过最大似然来进行学习。

    ICA的所有变种均要求$p(h)$是非高斯的。这是因为如果$p(h)$是具有高斯风量的独立先验，则W是不可识别的。这里和PCA是不同的。

    ICA多被用作在分离信号。
    
    [实例代码](./code/13-2.py)

1. 慢特征分析

    慢特征分析(SFA)是使用来自时间信号的信息学习不变特征的线性因子模型。基本思想是，与场景中描述作用的单个量度相比，场景的重要特征通常变化得非常缓慢。

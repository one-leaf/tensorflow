大部分的正则化都是对估计进行正则化，估计的正则化以偏差的增加换取方差的减少。正则化的目标是将除了包括真实的数据生成过程，还包括了许多其他可能的生成过程--方差（而不是偏差）造成的过拟合，改为只包括真实的数据生成过程。

1. 参数范数惩罚

    对目标函数 J 添加一个参数范数惩罚 $\Omega(\theta)$， 限制模型的的学习能力。最终的目标函数为：

    $$\hat J(\theta;X,y)=J(\theta;X,y)+\alpha\Omega(\theta)$$

    当训练 $\hat J$ 时，$\alpha\Omega(\theta)$ 会降低原始目标 $J$ 关于训练集的误差并同时减小参数 $\theta$ 的规模。

    另外参数包括了权重和偏置，但正则化只对权重进行惩罚，因为偏置的共享较少，对方差影响不大，而且如果惩罚偏置会造成难拟合。

    有些升级网络会分别对每一层单独设置正则化权重衰减参数，但调参困难，同时是全局共用一个权重衰减参数。

    1. L2参数正则化

        最简单的和常用的参数范数惩罚是权重衰减的L2参数范数惩罚，通过添加 $\Omega(\theta)=\frac 12||w||_2^2$ ,使权重更接近原点。L2也称为岭回归。

        假设没有偏置b，目标函数为：

        $$\hat J(w;X,y)=\frac {a}{2}w^Tw+J(w;X,y)$$

        对应的梯度为：

        $$\nabla_w\hat J(w;X,y)=aw+\nabla_wJ(w;X,y)$$

        使用单步梯度下降更新权重，即：

        $$w\leftarrow w-\epsilon (aw+\nabla_wJ(w;X,y))$$

        $$w\leftarrow (1-\epsilon a)w-\epsilon\nabla_wJ(w;X,y)$$

        先看不加正则项的情况，令 $w_0$ 为未正则化之前的w，则损失近似为：

        $$\hat J(\theta)=J(w_0)+\frac 12(w-w_0)^TH(w-w_0)$$

        H是J在$w_0$处计算的海森矩阵，当$\hat y$为最小值时，$w_0$最优，梯度为0，得J梯度为：

        $$\nabla_w\hat J(w)=H(w-w_0)=0$$    

        如果加上正则项，等式为：

        $$aw+H(w-w_0)=0$$

        推导：

        $$w=(H+aI)^{-1}Hw_0$$

        对H进行特征分解得（A是对角矩阵，Q是特征矩阵的标准正交基，$H=QAQ^T$）：

        $$w=(QAQ^T+aI)^{-1}QAQ^Tw_0$$
        $$=(QAQ^TQ+aIQ)^{-1}AQ^Tw_0$$
        $$=Q(A+aI)^{-1}AQ^Tw_0$$

        得出：

        按 $\frac \lambda{\lambda+a}$ 缩放H，所以当 $\lambda>>a$ 时，基本不受影响；当$\lambda<<a$时，影响很大，会严重收缩。这样就相当于“降噪”，对特征值大的不影响，对特征值小的减少到0，从而起到降低过拟合的作用。

    1. L1正则化

        对w的L1正则化,即绝对值和最小，定义为

        $$\Omega(\theta)=||w||_1=\sum_i|w_i|$$

        正则化后的目标函数为：

        $$\hat J(w;X,y)=a||w||_1+J(w;X,y)$$

        求梯度为(sign(w)为符号函数，正数为1，负数为-1)：

        $$\nabla_w\hat J(w;X,y)=asign(w)+\nabla_w J(w;X,y)$$

        因为引入了符号函数，将不是线性的缩放w，所以分开区间讨论：当 w >0 时，梯度会得到增加，而当 w<0 时，梯度会被降低，这样最终的结果会导致w不管特征值的大小，全部趋近于0，造成w稀疏。

        这种效果被用于特征选择机制，配合最大似然，可以有效去除无效的特征。

1. 作为约束的范数惩罚

    将通用的参数正则化代价函数

    $$\hat J(\theta;X,y)=J(\theta;X,y)+\alpha\Omega(\theta)$$

    转换为拉格朗日乘数法：

    $$\mathcal{L}(\theta,a;X,y)=J(\theta;X,y)+ a(\Omega(\theta)-k)$$ 

    求解：

    $$\hat \theta=arg\min_\theta \max_{a,a\geq 0}\mathcal{L}(\theta,a)$$

    可以观察到，当$\Omega(\theta)>k$时是增量，当$\Omega(\theta)<k$是减少。所有正值的a都在减小$\Omega(\theta)$。但即使a为最优值时，也不会导致 $\Omega(\theta)<k$ 。

    为了方便观察，将 a 固定到 a 的最优值 $\hat a$：

    $$\hat \theta=arg\min_\theta \mathcal{L}(\theta,\hat a)=arg\min_\theta J(\theta;X,y)+\hat a\Omega(\theta)$$

    这个表达式和正则化权重一致，所以可以将参数的范数惩罚看做是对权重的约束。

    相当于将参数约束到一个a的函数区间。增大a就会得到小的约束区域，减少a会得到一个大的约束区域。

    当然也可以通过修改梯度下降算法来显式的对w进行约束。

    不直接用正则化约束的原因是会导致目标函数非凸，有陷入局部极小的问题。

    其他推荐的策略是，约束神经网络层权重矩阵的每列的范数，而不是直接限制整个权重矩阵的F范数。分别限制每一列的范数，可以防止某一隐藏单元有非常大的权重。（矩阵的1范数是基于列的，F范数是整个的，2范数是最大特征值）

    [参考阅读](https://zhuanlan.zhihu.com/p/29360425)

1. 正则化和欠约束问题

    由于机器学习中大量依赖$X^TX$求逆，如果样本较少，某一个维度没有观察到方差，就会出现奇异矩阵，而正则化会让这个奇异矩阵可逆$X^TX+aI$（实际上w的初始化都是有值的，所以这个没用）。另外如果一个向量w可以完美分类会导致2w也完美分类，最终梯度下降会不断增加w的值，知道溢出，而正则化会阻止这个情况。

    总之，正则化有助于稳定欠定定向题。

1. 数据增强

    要泛化更好的最好办法是增加样本，由于样本总是有限，所以可以创造假数据插入到样本中。

    增加样本的时候，不能增加会改变类别的转换，如，b和d，6和9的识别，这种情况下水平翻转或旋转180度，就不适合。

    在神经网络的输入层引入噪声也是数据增强的一种。也可以直接向隐藏层输入噪声。

1. 噪声鲁棒性

    对某些模型而言，向输入添加方差极小的噪声等价于对权重施加了范数惩罚。一般情况下，注入噪声会比收缩参数强大，特别是添加到隐藏单元时会更加强大（Dropout）。

    另外一种正则化模型的噪声是加到权重，主要用在循环神经网络上。可以解释为关于权重的贝叶斯推断的随机实现，贝叶斯学习过程将权重视为不确定的，并通过概率分布表示这种不确定性。

    推导如下，下面是最小二乘法的公式：

    $$J=E_{p(x,y)}[\hat y(x)-y]^2$$

    网络权重中添加扰动$\epsilon_w = N(\epsilon;0,\mu I)$，则：

    $$\hat J_w=E_{p(x,y,\epsilon w)}[(\hat y_{\epsilon w}(x)-y)^2]$$
    $$=E_{p(x,y,\epsilon w)}[\hat y_{\epsilon w}^2(x)-2y\hat y_{\epsilon w}(x)+y^2]$$
    $$=E_{p(x,y)}[(\hat y(x)+\nabla w\hat y(x))^2-2y(\hat y(x)+\nabla w\hat y(x))+y^2]$$
    $$=E_{p(x,y)}[(\hat y^2(x)+2(\hat y(x))^2\nabla w+(\nabla w\hat y(x))^2-2y\hat y(x)-2y\nabla w\hat y(x)+y^2]$$
    $$=E_{p(x,y)}[(\hat y^2(x)-y)^2+2(\hat y(x))^2\nabla w+(\nabla w\hat y(x))^2-2y\nabla w\hat y(x)]$$
    $$=E_{p(x,y)}[(\hat y^2(x)-y)^2]+E_{p(x,y)}[2(\hat y(x))^2\nabla w+(\nabla w\hat y(x))^2-2y\nabla w\hat y(x)]$$
    $$=J+E_{p(x,y)}[(\hat y(x))^2(2\nabla w+(\nabla w)^2-\frac {2y}{\hat y(x)}\nabla w)]$$
    $$=J+E_{p(x,y)}[(\hat y(x))^2((\nabla w)^2+2\nabla w(1-\frac y{\hat y (x)})]$$

    由于到极值时，后者项相等，1-1为0，则简化为：
    
    $$\hat J_w=J+E_{p(x,y)}[||\nabla w\hat y(x)||^2]$$

    这种鼓励参数w变小，即推动模型进入对权重小的变化不敏感的区域，找到点不仅是极小点，还是由平坦区域包围的极小点。

    - 向输出目标注入噪声

        大多数数据集的y标签都有一定错误。错误的y不利于最大化交叉熵。为了避免这种情况，一种是显式的对标签上的噪声进行建模。假定训练集标记y是正确的概率为$1-\epsilon$,这个假设就很容易能和代价函数结合，不用显示的抽取噪声样本。例如标签平滑，将确切的分类目标从0和1替换为:$\frac{\epsilon}{k-1}$和$1-\epsilon$,正则化k个输出的softmax函数的模型。这个措施可以让模型不过分关注概率又不影响模型正确分类。

        第一种办法，直接改y：
        
        $L=-ylog(\hat y)$ 将 y 改为：$\epsilon(1-y)+(1-\epsilon)y$

        第二种办法，改损失函数：

        $L=-ylog(\hat y)$ 改为：$L=(1-\epsilon)ylog(\hat y)+\epsilon u(k)$ 。如果先验分布是均匀分布时， $u(k)=1/k$ ,k是分类的个数，让预测的结果同时拟合one-hot标签和先验分布。 

1. 半监督学习
            
    半监督学习是，P(x)产生的未标记样本和P(x,y)中标记的样本都用于估计P(x|y)，或根据x预测y。

    可以构建一个模型，生成模型P(x)或P(x,y)与判别模型P(y|x)共享参数，而不用分离无监督和监督部分。将P(x)的结构通过共享参数连接到P(x|y)，这样可以获得比纯生成或纯判别训练得到根号的权衡。

    - 自训练模型
    
        形式上，自训练模型有一个模型m、一个含标签训练数据集L和一个不含标签数据集U。每次迭代中，模型m会基于标签集C，为U中的样本x生成一个标签概率m(x)。如果m(x)大于阈值τ，我们就用p(x)=argmax m(x)为样本x生成一个伪标签（pseudo-label），然后把它归入训练集L中。

    [参考阅读](https://www.jqr.com/article/000264)

1. 多任务学习

    是通过合并几个任务中的样例来提高泛化的一种方式。当模型的一部分被多个额外的任务共享时，这部分将被约束为良好的值。

1. 提前终止

    当训练有足够的表示能力时，都会观察到验证集的误差随训练集的误差的降低反而升高。

    可以每次存储当验证集的误差降低时的模型，而不是存储训练集误差降低时的模型，当训练终止时，返回的是误差最低的模型，而不是最后的训练模型，这个就叫提前终止。

    可以理解为训练步数就是一个超参数，这个超参数在验证集上具有U性能曲线。通过控制训练步数来控制模型的有效容量。

    提前终止可以和其他正则化策略结合使用。

    有用的策略：

    - 在提前结束首轮训练后，第二轮将所有的数据都包括（含验证集），重新初始化训练，，但用第一轮训练的步数。

    - 保持首轮训练的参数，第二轮接着训练，将所有的数据都包括（含验证集），并监控损失函数值，达到第一轮同样的损失值时，停止。

    提前终止相当于L2正则化。

1. 参数绑定和参数共享
            
    在不能确定超参的时候，可以用两个相同的模型执行相同的分类任务，但输入的分布不同，然后用如下形式的参数范数惩罚：$\Omega(W_a,W_b)=||W_a-W_b||_2^2$。

    上面的参数范数惩罚只是一种，更流行的是使用约束，由于我们将各种模型或组件解释为共享唯一的一组参数，来强迫某些参数相等，这种办法称为参数共享。这样可以显著的减少模型的占用内存。

    1. 卷积神经网络

        最流行和最广泛使用参数共享的是卷积神经网络，自然属性中很多统计属性是不变的，所以CNN通过在图像多个位置共享参数来考虑这个特性。

1. 稀疏表示

    前面都是针对参数的，另外一种策略是针对激活单元，稀疏化激活单元，这种策略间接的对模型参数施加了复杂惩罚。

    定义h是x的一个函数，h表示了x，我们可以在损失函数中添加对表示的范数惩罚如下：

    $$\hat J(\theta;X,y)=J(\theta;X,y)+a\Omega(h)$$

    其中，a是权衡范数惩罚项的相对贡献。

    因为L1具有稀疏特性，最后导致h也具有稀疏性，相对代表了x也具有的稀疏性。其他的办法还有 Student-t 和 KL 散度惩罚，都是将表示中的元素约束到单位区间。

    还有一些办法通过激活值的约束来表示稀疏，例如正交匹配追踪（OMP-k），通过解决如下约束问题：

    $$arg\min_{h,||h||_0<k}||x=Wh||^2$$

    其中$||h||_0$是h中非零的个数，通过k指定允许的非0特征数量，可以将OMP-1成为非常有效的特征提取器。

1. Bagging 和其他集成方法

    Bagging 就是结合多个模型来降低泛化误差的技术，主要想法是分别训练几个不同的模型，然后让所有的模型表决测试样例的输出。这种被叫为模型平均。这种技术称为集成学习。

    模型平均的原因是不同的模型通常不会在测试集上产生完全相同的误差。

    假如有k个回归模型，每个模型在每个例子上的误差是$\epsilon_i$。这个误差的分布的方差为$E[\epsilon_i^2]=v$，且协方差为$E[\epsilon_i,\epsilon_j]=c$的多维正态分布，通过所有模型的平均误差为$\frac 14\sum_i\epsilon_i$。则期望是：

    $$E[(\frac 1k\sum_i\epsilon_i)^2]=\frac 1{k^2}[\sum_i (\epsilon_i^2+\sum _{j\neq i}\epsilon_i\epsilon_j) ]=\frac 1kv+\frac {k-1}kc$$

    当各个模型的误差相关时,c=v，则均方误差为v，即模型平均没有益处；当各个模型的误差不相关时，v=0，则均方误差为v/k；即误差随着模型的规模数线性减少。

    不同的集成办法，可以允许用不同的算法和不同的损失函数。Bagging 允许使用相同的模型、训练算法和损失函数，将数据集分为k个，每个数据集重复采用，这样造成模型会高概率缺失某些特征，从而导致模型之间的差异。然后将所有的结果汇总就能得到高的鲁棒性。

    目前机器学习比赛的取胜算法，通常超过几十种模型平均的方法。

1. Dropout

    Dropout 提供了廉价的Bagging集成近似，能够训练和评估指数级数量的神经网络。

    Dropout 的集成包括所有从基础网络去除非输出单元后形成的子网络。在训练中采用小批量的随机梯度下降法。通常设置为0.5的概率。

    权重比例推断比蒙特卡罗近似的效果更好，也比其他的开销小的正则化方法更有效。
    
    Dropout可以和其他形式的正则化方式相结合。

    Dropout 优点：

    - 计算方便

    - 对适用的模型或训练过程无限制

    问题：

    - 由于是正则化技术，减少了模型的有效容量，所以需要增大模型规模和训练迭代次数。对于非常大的训练集而言，正则化带来的减少泛化误差可能会很小。

    - 当只有极少的样本时，Dropout 不会有效。

    Dropout 衍生出 DropConnect 和随机池化等方法，不过目前使用最广的还是 Dropout。

    权重直接乘以一个实值（$\mu = N(1,I)$）的效果比基于二值掩码的dropout表现的更好。

    Dropout和Bagging相比，除了集成以外，还共享隐藏单元。由于隐藏单元不仅要表现良好，而且还要在模型之间进行交换和互换，这样会带来额外的改进。

    Dropout强大的部分原因还来自施加到隐藏单元的掩码噪声。迫使模型学习到信息的额外冗余编码，可以充分利用原始信息。

    Dropout的噪声是乘性的，而不是相加，这样导致模型不能简单的将h放大，用这种病态的去解决噪声的鲁棒性问题。

    批标准化也向隐藏单元注入了乘性噪声，带来了同样的正则化效果。所以有时没有必要再使用Dropout。

1. 对抗训练

    对于x，通过优化过程故意构造数据点x'，x和x‘非常接近，人类的观察者不会察觉原始样本和对抗样本的差异，但导致网络产生100%的识别错误。

    不考虑对抗训练在安全性上的应用，我们可以通过对抗训练来减少原有独立同分布的测试集的错误率，即在对抗扰动的训练样本上训练网络。

    对抗样本起作用的原因是过渡线性，由于神经网络是基于线性块构建的，所以很容易优化，同时也容易得到快速的改变。对抗训练通过鼓励网络在训练数据附近的局部区域恒定来限制这一高度敏感的局部线性行为。

    对抗样本有助于体现积极正则化与大型函数族结合的力量。也提供了一种实现半监督学习的办法，这样可以鼓励模型对微小变化更具有鲁棒性。

1. 切面距离、正切传播和流形正切分类器

    正切传播算法使神经网络的输出f(x)对已知的变化因素是不变的，这种变化延着相同样本聚集的流形移动，就是要求$\nabla_xf(x)$与已知流形的切向$v_i$正交，或者等价通过正则化惩罚$\Omega$使f在x的$v_i$方向的导数较小：

    $$\Omega(f)=\sum_i((\nabla_xf(x)^Tv_i))^2$$

    优点是可以按指定的方向进行抵抗扰动，缺点是只能抵抗无穷小的扰动；另外很难在relu上使用这种方法，因为relu的导数是固定的，不像sigmod或tanh可以通过较大的权重到高值处于饱和来收缩导数。

    流形正切分类器不需要知道切线向量的先验，自编码器可以估算流形的切向量。算法为：使用自编码器通过无监督学习来学习流形的结构，以及如正切传播一样使用这些切面正则化神经网络分类器。



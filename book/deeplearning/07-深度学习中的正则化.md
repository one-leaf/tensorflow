大部分的正则化都是对估计进行正则化，估计的正则化以偏差的增加换取方差的减少。正则化的目标是将除了包括真实的数据生成过程，还包括了许多其他可能的生成过程--方差（而不是偏差）造成的过拟合，改为只包括真实的数据生成过程。

1. 参数范数惩罚

    对目标函数 J 添加一个参数范数惩罚 $\Omega(\theta)$， 限制模型的的学习能力。最终的目标函数为：

    $$\hat J(\theta;X,y)=J(\theta;X,y)+\alpha\Omega(\theta)$$

    当训练 $\hat J$ 时，$\alpha\Omega(\theta)$ 会降低原始目标 $J$ 关于训练集的误差并同时减小参数 $\theta$ 的规模。

    另外参数包括了权重和偏置，但正则化只对权重进行惩罚，因为偏置的共享较少，对方差影响不大，而且如果惩罚偏置会造成难拟合。

    有些升级网络会分别对每一层单独设置正则化权重衰减参数，但调参困难，同时是全局共用一个权重衰减参数。

    1. L2参数正则化

        最简单的和常用的参数范数惩罚是权重衰减的L2参数范数惩罚，通过添加 $\Omega(\theta)=\frac 12||w||_2^2$ ,使权重更接近原点。L2也称为岭回归。

        假设没有偏置b，目标函数为：

        $$\hat J(w;X,y)=\frac {a}{2}w^Tw+J(w;X,y)$$

        对应的梯度为：

        $$\nabla_w\hat J(w;X,y)=aw+\nabla_wJ(w;X,y)$$

        使用单步梯度下降更新权重，即：

        $$w\leftarrow w-\epsilon (aw+\nabla_wJ(w;X,y))$$

        $$w\leftarrow (1-\epsilon a)w-\epsilon\nabla_wJ(w;X,y)$$

        先看不加正则项的情况，令 $w_0$ 为未正则化之前的w，则损失近似为：

        $$\hat J(\theta)=J(w_0)+\frac 12(w-w_0)^TH(w-w_0)$$

        H是J在$w_0$处计算的海森矩阵，当$\hat y$为最小值时，$w_0$最优，梯度为0，得J梯度为：

        $$\nabla_w\hat J(w)=H(w-w_0)=0$$    

        如果加上正则项，等式为：

        $$aw+H(w-w_0)=0$$

        推导：

        $$w=(H+aI)^{-1}Hw_0$$

        对H进行特征分解得（A是对角矩阵，Q是特征矩阵的标准正交基，$H=QAQ^T$）：

        $$w=(QAQ^T+aI)^{-1}QAQ^Tw_0$$
        $$=(QAQ^TQ+aIQ)^{-1}AQ^Tw_0$$
        $$=Q(A+aI)^{-1}AQ^Tw_0$$

        得出：

        按 $\frac \lambda{\lambda+a}$ 缩放H，所以当 $\lambda>>a$ 时，基本不受影响；当$\lambda<<a$时，影响很大，会严重收缩。这样就相当于“降噪”，对特征值大的不影响，对特征值小的减少到0，从而起到降低过拟合的作用。

    1. L1正则化

        对w的L1正则化,即绝对值和最小，定义为

        $$\Omega(\theta)=||w||_1=\sum_i|w_i|$$

        正则化后的目标函数为：

        $$\hat J(w;X,y)=a||w||_1+J(w;X,y)$$

        求梯度为(sign(w)为符号函数，正数为1，负数为-1)：

        $$\nabla_w\hat J(w;X,y)=asign(w)+\nabla_w J(w;X,y)$$

        因为引入了符号函数，将不是线性的缩放w，所以分开区间讨论：当 w >0 时，梯度会得到增加，而当 w<0 时，梯度会被降低，这样最终的结果会导致w不管特征值的大小，全部趋近于0，造成w稀疏。

        这种效果被用于特征选择机制，配合最大似然，可以有效去除无效的特征。

    1. 作为约束的范数惩罚

        将通用的参数正则化代价函数

        $$\hat J(\theta;X,y)=J(\theta;X,y)+\alpha\Omega(\theta)$$

        转换为拉格朗日乘数法：

        $$\mathcal{L}(\theta,a;X,y)=J(\theta;X,y)+ a(\Omega(\theta)-k)$$ 

        求解：

        $$\hat \theta=arg\min_\theta \max_{a,a\geq 0}\mathcal{L}(\theta,a)$$

        可以观察到，当$\Omega(\theta)>k$时是增量，当$\Omega(\theta)<k$是减少。所有正值的a都在减小$\Omega(\theta)$。但即使a为最优值时，也不会导致 $\Omega(\theta)<k$ 。

        为了方便观察，将 a 固定到 a 的最优值 $\hat a$：

        $$\hat \theta=arg\min_\theta \mathcal{L}(\theta,\hat a)=arg\min_\theta J(\theta;X,y)+\hat a\Omega(\theta)$$

        这个表达式和正则化权重一致，所以可以将参数的范数惩罚看做是对权重的约束。

        相当于将参数约束到一个a的函数区间。增大a就会得到小的约束区域，减少a会得到一个大的约束区域。

        当然也可以通过修改梯度下降算法来显式的对w进行约束。

        不直接用正则化约束的原因是会导致目标函数非凸，有陷入局部极小的问题。

        其他推荐的策略是，约束神经网络层权重矩阵的每列的范数，而不是直接限制整个权重矩阵的F范数。分别限制每一列的范数，可以防止某一隐藏单元有非常大的权重。（矩阵的1范数是基于列的，F范数是整个的，2范数是最大特征值）

        [参考阅读](https://zhuanlan.zhihu.com/p/29360425)

    1. 正则化和欠约束问题

        由于机器学习中大量依赖$X^TX$求逆，如果样本较少，某一个维度没有观察到方差，就会出现奇异矩阵，而正则化会让这个奇异矩阵可逆$X^TX+aI$（实际上w的初始化都是有值的，所以这个没用）。另外如果一个向量w可以完美分类会导致2w也完美分类，最终梯度下降会不断增加w的值，知道溢出，而正则化会阻止这个情况。

        总之，正则化有助于稳定欠定定向题。

    1. 数据增强

        要泛化更好的最好办法是增加样本，由于样本总是有限，所以可以创造假数据插入到样本中。

        增加样本的时候，不能增加会改变类别的转换，如，b和d，6和9的识别，这种情况下水平翻转或旋转180度，就不适合。

        在神经网络的输入层引入噪声也是数据增强的一种。也可以直接向隐藏层输入噪声。

    1. 噪声鲁棒性

        对某些模型而言，向输入添加方差极小的噪声等价于对权重施加了范数惩罚。一般情况下，注入噪声会比收缩参数强大，特别是添加到隐藏单元时会更加强大（Dropout）。

        另外一种正则化模型的噪声是加到权重，主要用在循环神经网络上。可以解释为关于权重的贝叶斯推断的随机实现，贝叶斯学习过程将权重视为不确定的，并通过概率分布表示这种不确定性。

        推导如下，下面是最小二乘法的公式：

        $$J=E_{p(x,y)}[\hat y(x)-y]^2$$

        网络权重中添加扰动$\epsilon_w = N(\epsilon;0,\mu I)$，则：

        $$\hat J_w=E_{p(x,y,\epsilon w)}[(\hat y_{\epsilon w}(x)-y)^2]$$
        $$=E_{p(x,y,\epsilon w)}[\hat y_{\epsilon w}^2(x)-2y\hat y_{\epsilon w}(x)+y^2]$$
        $$=E_{p(x,y)}[(\hat y(x)+\nabla w\hat y(x))^2-2y(\hat y(x)+\nabla w\hat y(x))+y^2]$$
        $$=E_{p(x,y)}[(\hat y^2(x)+2(\hat y(x))^2\nabla w+(\nabla w\hat y(x))^2-2y\hat y(x)-2y\nabla w\hat y(x)+y^2]$$
        $$=E_{p(x,y)}[(\hat y^2(x)-y)^2+2(\hat y(x))^2\nabla w+(\nabla w\hat y(x))^2-2y\nabla w\hat y(x)]$$
        $$=E_{p(x,y)}[(\hat y^2(x)-y)^2]+E_{p(x,y)}[2(\hat y(x))^2\nabla w+(\nabla w\hat y(x))^2-2y\nabla w\hat y(x)]$$
        $$=J+E_{p(x,y)}[(\hat y(x))^2(2\nabla w+(\nabla w)^2-\frac {2y}{\hat y(x)}\nabla w)]$$
        $$=J+E_{p(x,y)}[(\hat y(x))^2((\nabla w)^2+2\nabla w(1-\frac y{\hat y (x)})]$$

        由于到极值时，后者项相等，1-1为0，则简化为：
       
        $$\hat J_w=J+E_{p(x,y)}[||\nabla w\hat y(x)||^2]$$

        这种鼓励参数w变小，即推动模型进入对权重小的变化不敏感的区域，找到点不仅是极小点，还是由平坦区域包围的极小点。

        - 向输出目标注入噪声

            大多数数据集的y标签都有一定错误。错误的y不利于最大化交叉熵。为了避免这种情况，一种是显式的对标签上的噪声进行建模。假定训练集标记y是正确的概率为$1-\epsilon$,这个假设就很容易能和代价函数结合，不用显示的抽取噪声样本。例如标签平滑，将确切的分类目标从0和1替换为:$\frac{\epsilon}{k-1}$和$1-\epsilon$,正则化k个输出的softmax函数的模型。这个措施可以让模型不过分关注概率又不影响模型正确分类。

            第一种办法，直接改y：
            
            $L=-ylog(\hat y)$ 将 y 改为：$\epsilon(1-y)+(1-\epsilon)y$

            第二种办法，改损失函数：

            $L=-ylog(\hat y)$ 改为：$L=(1-\epsilon)ylog(\hat y)+\epsilon u(k)$ 。如果先验分布是均匀分布时， $u(k)=1/k$ ,k是分类的个数，让预测的结果同时拟合one-hot标签和先验分布。 

    1. 半监督学习
            

            


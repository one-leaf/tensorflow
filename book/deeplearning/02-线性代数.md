- 标量、向量、矩阵、张量

    - 标量(scalar)： 单独的数

    - 向量(vector)： 一列数，可以看做空间中的点

    - 矩阵(matrix)： 二维数组

    - 张量(tensor)： 多维数组

    - 转置(transpose)，将矩阵按对角线为轴镜像: 

        $$ A_{i,j}^T=A_{j,i} $$

        >例子：
        >
        >$$ A = \begin{bmatrix} A_{1,1} & A_{1,2} \\ A_{2,1} & A_{2,2} \\ A_{3,1} & A_{3,2} \end{bmatrix}\Rightarrow A^T = \begin{bmatrix} A_{1,1} & A_{2,1} & A_{3,1} \\ A_{1,2} & A_{2,2} & A_{3,2} \end{bmatrix} $$

- 矩阵和向量相乘

    如果A的形状是(m,n), B的形状是(n,p), C的形状是(m,p)，则可以书写为 C = AB

    定义：

    $$ C_{i,j} = \sum_{k} A_{i,k}B_{k,j} $$

    注意不同于点积 A * B

    一些性质：
    
    $$ A(B+C) = AB + AC $$
    
    $$ A(BC) = (AB)C $$

    $$ x^Ty=y^Tx $$

    $$ (AB)^T=B^TA^T $$

    $$ x^Ty=(x^Ty)^T=y^Tx $$

- 单位矩阵和逆矩阵

    任何向量与单位矩阵相乘都不会改变

    $$ \begin{bmatrix} 1&0&0 \\ 0&1&0 \\ 0&0&1 \end{bmatrix} = I_3 $$

    $I$ 就是单位矩阵

    $A$ 的逆矩阵为 $A^{-1}$ 

    $$ A^{-1}A=I_n $$

- 线性相关和生成子空间

    线性方程组

    $$ Ax = b $$

    $A$ 为已知矩阵，$b$为已知向量，求解向量$x$

    展开：

    $$ A_{1,1}x_1+A_{1,2}x_2+...+A_{1,n}x_n=b_1 $$
    $$ A_{2,1}x_1+A_{2,2}x_2+...+A_{2,n}x_n=b_2 $$
    $$ ... $$
    $$ A_{m,1}x_1+A_{m,2}x_2+...+A_{m,n}x_n=b_m $$

    如果逆矩阵 $A^{-1}$ 存在，则上面有唯一解，反之则存在无解或存在无限多个解

    方程的解可以看做A的列向量从原点出发的不同方向，确定有多少种办法可以达到向量b；x的每个元素为我们应该沿着这个方向走的距离。

    $$ A_x=\sum_{i} x_iA_{:,i} $$

    这种操作就称为线性组合

    一组向量的生成子空间是原始向量线性组合后所能抵达的点的集合

    确定 $Ax=b$ 是否有解，相当于确定向量$b$是否在$A$列向量的生成子空间内。这个子空间称为$A$的列空间或$A$的值域。

    向量中的冗余称为线性相关，如果一组向量中的任意一个向量都不能表示成其他向量的线性组合，那么称为线性无关。

    列线性相关的矩阵被称为奇异的。如果矩阵A是一个方阵并且不是一个奇异的，可以用矩阵逆求解。

- 行列式

    矩阵的行列式$|A|$是一个可以从方形矩阵（方阵）计算出的特别的数。用于解线性方程或找逆矩阵。

    2x2矩阵：

    $$A=\begin{bmatrix} x_{11} & x_{12} \\ x_{21} & x_{22} \end{bmatrix}$$
    $$|A|=x_{11}*x_{22}-x_{12}*x_{21}$$

    3x3 矩阵：

    $$A=\begin{bmatrix} a & b & c \\ d & e & f \\ g & h & i \end{bmatrix}$$
    $$|A|=a*\begin{bmatrix} e&f \\ h&i \end{bmatrix}-b*\begin{bmatrix} d&f \\ g&i \end{bmatrix}+c*\begin{bmatrix} d&e \\ g&h \end{bmatrix}$$
    $$|A|=a(ei-fh)-b(di-fg)+c(dh-eg)$$

    4x4 和更大的矩阵：
    
    $$A=\begin{bmatrix} a&b&c&d \\ e&f&g&h \\ i&j&k&l \\ m&n&o&p \end{bmatrix}$$

    $$
    |A|=a*\begin{bmatrix} &f&g&h \\ &j&k&l \\ &n&o&p \end{bmatrix}
    -b*\begin{bmatrix} e&&g&h \\ i&&k&l \\ m&&o&p \end{bmatrix}
    +c*\begin{bmatrix} e&f&&h \\ i&j&&l \\ m&n&&p \end{bmatrix}
    -d*\begin{bmatrix} e&f&g& \\ i&j&k& \\ m&n&o& \end{bmatrix}
    $$

    注意 +-+- 的规律，(+a... -b... +c... -d...) 依次类推。

    这个称为拉普拉斯展开。

- 范数

    范数是满足下列性质的函数:

    $$ f(x)=0 \Rightarrow x=0 $$
    $$ f(x+y) \le f(x) + f(y) $$
    $$ \forall \alpha\in \mathbb{R}, f(\alpha x)=|\alpha|f(x)  $$

    向量的范数：

    - 0 范数：向量中非零元素的个数
    - 1 范数：绝对值之和

    $$ ||x||_1=\sum _i|x_i| $$

    - 2 范数：通常意义上的模，各元素的平方和再开方

    $$ ||x||_2=\sqrt {\sum _ix_i^2} $$

    - 无穷范数或最大范数：就是取向量的最大值

    $$ ||x||_{\infty} =\max_j |x_i| $$
    $$ ||x||_{-\infty} =\min_j |x_i| $$

    衡量矩阵的大小为范数（norm）

    - p 范数：向量绝对值的p次方和的1/p次幂

    $$ ||x||_p = (\sum_i|x_i|^p)^{1/p} $$


    当p=2, p 范数等于L2范数，称为欧几里得范数，表示从原点出发到向量x确定的点的欧几里得距离

    L2范数省略开平方后称为平方L2范数。

    平方L2范数在原点附近的增长很缓慢，所有某些场合，采用L1范数，简化为：

    $$ ||x||_1=\sum_i|x_i| $$

    L1范数有时候可以作为统计非0元素数目的替代。

    矩阵的范数：

    - 1 范数，列和范数，所有矩阵列向量之和的最大值

    $$ ||A||_1 = max_j \sum_{i=1}^m|a_{i,j}| $$

    - 2 范数，谱范数，即$A^TA$矩阵的最大特征值的开平方。

    $$ ||A||_2 = \sqrt {\lambda_1} $$

    $\lambda_1$为$A^TA$的最大特征值。

    - 无穷范数或最大范数，行和范数，即所有矩阵行向量绝对值之和的最大值。

    $$ ||A||_F = \max_i\sum_{j=1}^n|a_{i,j}|$$

    - 范数也可以用来衡量矩阵的大小，称为Frobenius范数，简称F范数，就是矩阵的每个元素的平方和的开方。

    $$ ||A||_F = \sqrt {\sum_{i,j}A_{i,j}^{2}} $$

    两个向量的点积可以用范数来表示:

    $$ x^Ty=||x||_2||y||_2cos\theta $$

    $\theta$ 表示 x 和 y 之间的夹角 

    >例子，求 矩阵$A =\begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{bmatrix}$ 的L2范数
    >
    >矩阵范数定义
    >
    >$$ ||A||^2_2= \sqrt {\lambda_1} $$
    >
    >$\lambda_1$为矩阵$A$的最大特征值
    >
    >$$ \lambda = A^T A=\begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{bmatrix}*\begin{bmatrix} 1 & 4 \\2 & 5 \\ 3 & 6 \end{bmatrix}$$
    >$$=\begin{bmatrix} 1*1+2*2+3*3 & 1*4+2*5+3*6 \\ 4*1+5*2+6*3 & 4*4+5*5+6*6 \end{bmatrix}$$
    >$$=\begin{bmatrix} 14 & 32 \\ 32 & 77 \end{bmatrix}$$
    >$$|\lambda E-A|=\begin{bmatrix} \lambda -14 & -32 \\ -32 & \lambda -77 \end{bmatrix}=0$$
    >$$\Rightarrow(\lambda-14)*(\lambda-77)-(-32*-32)=0$$
    >$$\Rightarrow\lambda^2-91\lambda+54=0$$
    >$$\Rightarrow{(\lambda-{\frac {91}{2}})} ^2-\frac {91^2}{4}+54=0$$
    >$$\lambda= \pm\sqrt{\frac {91^2}{4}-54}+\frac{91}{2}$$
    >$$\lambda=[90.4\ 0.6]$$
    >$$||A||^2_2=\sqrt{\max_i\lambda}=\sqrt {90.4}=9.5079$$

- 特殊类型的矩阵和向量

    对角矩阵：只有主对角线上含有非零元素，其余都是零。

    对称矩阵：矩阵转置后和原矩阵相等。 $A=A^T$

    单位向量：具有单位范数的向量 $||x||_2=1$

    正交矩阵：行向量和列向量是分别标准正交的方阵， $A^TA=AA^T=I$

- 特征分解

    将矩阵分解为一组特征向量和特征值。

    方阵A的特征向量是指与A相乘后相当于对该向量进行缩放的非零向量v

    $$ Av=\lambda v $$

    $\lambda$ 就是这个特征向量对应的特征值

    >例子：求$A=\begin{bmatrix} 1& 1 & -1\\1 &-2&2 \\-3&1&3 \end {bmatrix}$ 的特征值
    >
    >1. 根据特征多项式得
    >
    >    $$|\lambda E-A|=\begin{bmatrix} \lambda-1& -1 & 1\\-1 &\lambda+2&-2 \\3&-1&\lambda-3 \end {bmatrix}=0$$
    >
    >2. 第1行减去第三行，得到一个0
    >
    >    $$=\begin{bmatrix} \lambda-4& 0 & 4-\lambda\\-1 &\lambda+2&-2 \\3&-1&\lambda-3 \end {bmatrix}$$
    >
    >3. 第3列加上第一列，得到第二个0
    >
    >    $$=\begin{bmatrix} \lambda-4& 0 & 0\\-1 &\lambda+2&-3 \\3&-1&\lambda \end {bmatrix}$$
    >
    >4. 展开多项式
    >
    >    $$=(\lambda-4)\begin{bmatrix} \lambda+2&-3 \\-1&\lambda \end {bmatrix} - 0*... + 0*...$$
    >    $$=(\lambda-4)((\lambda+2)(\lambda)-(-1*-3))$$
    >    $$=(\lambda-4)(\lambda^2+2\lambda-3)$$
    >    $$=(\lambda-4)(\lambda-1)(\lambda+3)=0$$
    >
    >5. 解得
    >
    >    $$\lambda=[4,1,-3]$$

    矩阵A有n个线性无关的特征向量 {$v^{(1)},...,v^{(1)}$,对应的特征值{$\lambda^{(1)},...,\lambda^{(n)}$}。将特征向量连接成一个矩阵，每一列是一个特征向量: $V=[v^{(1)},...,v^{(n)}]$，类似特征值也可以接连成一个向量，因此A的特征分解可以记为：

    $$A=Vdiag(\lambda)V^{(-1)}$$

- 奇异值分解

    将矩阵分解为奇异向量和奇异值。非方阵只能用奇异值分解。

    $$A=UDV^T$$

    假设 A:(m,n) 则 U:(m,m) D:(m,n) V:(n,n), 其中U和V都为正交矩阵，D为对角矩阵（不一定是方阵）

    对角矩阵D的对角线上的元素为 A 的奇异值，U的列向量为左奇异向量，V的列向量为右奇异向量。

- 伪逆

    解非方矩阵

    $$ A^+ = VD^+U^T $$ 

    U、D、V是A奇异值分解后得到的矩阵

- 迹运算

    迹运算返回的是矩阵对角元素的和：

    $$ Tr(A) = \sum _iA_{i,i} $$

    相当于另外一种范式

- 行列式

    行列式，det(A) ,是将方阵A映射到实数的函数，行列式等于矩阵特征值的乘积。

- 主成分分析（PCA）

    简单的机器学习算法，通过压缩信息，编码和解码

- 协方差矩阵

    - 基本概念
    
        - 均值

            $$\overline s=\frac 1n\sum _{i=1}^nX_i$$

        - 标准差

            $$\sigma=\sqrt {\frac 1n\sum _{i=1}^n(x_i-\overline x)^2}$$

        - 方差

            $$\sigma^2=\frac 1n\sum _{i=1}^n(x_i-\overline x)^2$$
        
        无偏估计时，将n改为n-1
    
    - 协方差

        需要度量两个相同长度向量之间的关系，仿造方差的定义定义协方差矩阵：

        $$cov(x,y)=\frac 1n\sum _{i=1}^n(x_i-\overline x)(y_i-\overline y)$$

        同样无偏估计时，将n改为n-1

        协方差值相关系数定义为：
        
        $$\eta=\frac {cov(x,y)}{\sigma_x\sigma_y}$$
        
        协方差值相关系数在[-1,1]之间。0是无关，1是正相关，-1是负相关。


    - 协方差矩阵

        $$C_{n,n}=(c_{i,j});c_{i,j}=cov(dim_i,dim_j)$$

        协方差(i,j)=（第i列的所有元素-第i列的均值）*（第j列的所有元素-第j列的均值）

        例如三维的协方差矩阵为：

        $$\begin{bmatrix} cov(x,x)& cov(x,y) & cov(x,z)\\cov(y,x) &cov(y,y)&cov(y,z) \\cov(z,x)&cov(z,y)&cov(z,z) \end {bmatrix}$$

        可见，协方差矩阵是一个对称矩阵，对角线是各个维度的方差。
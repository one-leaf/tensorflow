深度学习中难以处理的推断问题通常是由于结构化图模型中潜变量的相互作用。但隐藏单元存在连接的半受限玻尔兹曼机或一个深度玻尔兹曼机被分为多层 ，这样就很难处理其后验分布。

1. 把推断视为优化问题

    为了构造这个优化问题，假设需要观察数据的对数概率$\log p(x;\theta)$,如果边缘化消去潜变量h的操作很费时，则难以计算对数概率。这时可以考虑通过计算一个证据下界即$\log p(x;\theta)$的下界$L(x,\theta,q)$，这个也称为负变分自由能。具体定义如下：

    $$L(x,\theta,q)=\log p(x;\theta)-D_{KL}(q(h|x)||p(h|x;\theta))$$

    其中q是关于h的一个任意概率分布。

    $\log p(x;\theta)$和$L(x,\theta,q)$之间的距离为KL散度，KL散度总是为正数，所以 $L$ 总是小于对数概率。

    我们可以选择一个合适的分布q，让 $L$ 好计算，这个分布越和p相近，这个近似越完美。

    因此我们可以将推断问题转为找一个分布q使得 $L$ 最大化问题。在限定q的过程中不求彻底最大化 $L$ ，而是显著的提升 $L$ 。

    再将L简化为：

    $$L(x,\theta,q)=\log p(x;\theta)-D_{KL}(q(h|x)||p(h|x;\theta))$$

    $$=\log p(x;\theta)-\mathbb E_{h\sim q}\log \frac{q(h|x)}{p(h|x)}$$

    $$=\log p(x;\theta)-\mathbb E_{h\sim q}\log \frac{q(h|x)}{\frac{p(h,x;\theta)}{p(x;\theta)}}$$

    $$=\log p(x;\theta)-\mathbb E_{h\sim q}[\log q(h|x)-\log p(h,x;\theta)+\log p(x;\theta)]$$

    $$=-\mathbb E_{h\sim q}[\log q(h|x)-\log p(h,x;\theta)]$$

    即：

    $$L(x,\theta,q)=\mathbb E_{h\sim q}[\log q(h,x)]+H(q)$$

1. 期望最大化

    一个最大化 $L$ 的方法是期望最大化(EM)，EM算法通过两步交替迭代，直到收敛。

    *   E步，对我们训练样本 $x_i$，令 $q(h_i|x)=p(h_i|x_i;\theta_0)$，这表示q在$\theta_0$下定义，但改变$\theta$时，$p(h|x;\theta)$ 也会相应变化，但$q(h|x)$不变，且等于 $p(h|x;\theta_0)$。

    *   M步，选择优化算法最大化$L(x,\theta,q)$。

    即，第一步更新分布q来最大化$L$,第二步更新$\theta$来最大化$L$。

    这里一个关键特性是当更新到另外一个$\theta$时，还是使用旧的q分布。

1. 最大后验推断和稀疏编码

    推断的定义为给定一些其他变量的情况下，计算某些变量概率分布的过程。当训练一个有潜变量的概率模型时，通常关注 $p(h|x)$。即计算：

    $$h^{*}=\argmax_h p(h|x)$$

    这个被称为最大后验推断，简称 MAP 推断。MAP 推断并不是一种近似推断， 如果希望设计一种最大化 $L(x,h,q)$ 的过程，则可以把 MAP 推断视为输出一个 q 值的学习过程是有帮助的，这时可以将 MAP 视为 q 的近视推断，因为无法得到一个精确的 q。

    根据：

    $$L(x,\theta,q)=\mathbb E_{h\sim q}[\log q(h,x)]+H(q)$$

    限定 q 满足 Dirac 分布:

    $$q(h|v)=\delta (h-\mu)$$

    这样可以通过 $\mu$ 来控制 q 的分布，丢弃L中不随 $\mu$ 变化的项目，得到：

    $$\mu^*=\argmax_h \log p(h=\mu, x)$$

    这样就可以用EM算法来训练，最终会使得 $L=\log p(x)$ 。

    我们再审视稀疏编码，其分布 p(x|h) 很难处理，无论高斯模型，还是对数似然都很难学习，这时我们可以通过 MAP 推断以及最大化以 h 为中心的Dirac分布来学习模型参数。

    将训练集所有的向量 h 拼接为矩阵 H，将所有的向量 x 组成矩阵 X：

    则稀疏编码问题转为最小化：

    $$J(H,W)=\sum_{i,j}|H_{i,j}|+\sum_{i,j}(X-HW^T)^2_{i,j}$$

    为了避免训练出极端小的 H 和极端大的 W，在训练过程中对权重进行加以衰减或对H列范数加以限制。

    这样就可以交替训练 H和W来得到最小化的J。

1. 变分推断和变分学习

    变分学习的核心思想就是在一个关于q的有约束的分布族上最大化L,选择这个分布族时应该考虑到计算$\mathbb E_q\log p(h,x)$的难度。常见的变分学习方法是加入一些限制，使得q是一个因子分布：

    $$q(h|x)=\prod_iq(h_i|x)$$

    这个被称为均值场方法。更通用的，可以通过选择分布q的形式来选择任何图模型的结构，这种图模型方法称为结构化变分推断。


    变分方法的优点是，不需要为分布q设定一个特定的参数化形式。当设定好如何分解后，通过优化问题来找到在这些分解限制下最优的概率分布，这样不需要过多的人工选择模型。

1. 离散型潜变量

    定义一个分布q，q的每一个因子都由一个离散状态的表格定义，这样，h是二值的，q可以根据每一个h分解，可以用一个$\hat h$的向量表达q的分布，$\hat h$中的每一个元素都代表了额一个概率，即：$q(h_i=1|x)=\hat h_i$

    确定q的分布后就可以优化参数了。可以用衰减的技巧来最小化L。

1. 变分法

    一般机器学习的技巧都是寻找一个向量$\theta$来最小化函数$j(\theta)$，这个步骤可以利用多元微积分和线性代数完成找到向量梯度为0的临界点 $\nabla_\theta J(\theta)=0$ 。某些时候需要解一个函数 f(x) ，如找到一些随机变量的概率密度分布函数，这个就需要用到变分法。

    函数 f(x) 的函数 被称为泛函 $J[f]$ ，然后可以对泛函$J[f]$求关于$f(x)$的导数得到泛函导数，也称为变分导数 $\frac {\delta}{\delta f(x)}J$:

    $$\frac {\delta}{\delta f(x)}\int g(f(x),x)dx=\frac{\partial}{\partial_y}$$
    
    将f(x)看作一个有着无穷不可数多元素的向量，简化上式为：

    $$\frac {\partial}{\partial \theta_i}\sum_j g(\theta_j,j)=\frac {\partial}{\partial \theta_i}g(\theta_i,i)$$

    这样我们可以通过寻找一个函数使得泛函导数的每个点都为0，来优化这个泛函。

    








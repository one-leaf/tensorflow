目标是寻找神经网络上的一组参数$\theta$，它能显著的降低代价函数$J(\theta)$。该代价函数包括性能评估和正则化项。

1. 学习和纯优化有什么不同

    用于深度模型的优化和传统不同，深度模型不会直接去更新我们关注的性能度量P，只是间接的优化P，通过降低代价函数$J(theta)$来提高P。纯优化是直接最小化目标J本身。

    通常代价函数写为训练集上的平均：

    $$J(\theta)=\mathbb E_{(x,y)\sim\hat p_{data}}L(f(x;\theta),y)$$

    $L$是每个样本的损失函数，$f(x;\theta)$是输入x时所预测的输出，$\hat p_{data}$ 是经验分布，$y$是目标输出。 通常我们更希望的最小化全部的数据分布$p_{data}$，而不是训练集上的经验分布$\hat p_{data}$。

    1. 经验风险最小化

        目标是降低上面所示的期望泛化误差，这个数据量被称为风险。将机器学习问题转化回一个优化问题的最简单办法是最小化训练集上的期望损失。我们叫最小化经验风险。这种训练过程叫经验风险最小化，即：

        $$J(\theta)=\mathbb E_{(x,y)\sim\hat p_{data}}L(f(x;\theta),y)=\frac 1m\sum_{i=1}^mL(f(x_i;\theta),y_i)$$

        m是样本的个数，最小化经验风险很容易过拟合。最有效的还是算法还是基于梯度下降的。深度学习中很少使用经验风险最小化。

    2. 代理损失函数和提前终止

        我们真正关心的损失函数并不能被高效的优化，这种情况下，我们通常会优化代理损失函数。

        例如分类[0,1]的损失是不可解的，我们通常使用负对数似然来代替[0,1]。而且这个效果会比直接学习[0,1]更好，因为即使到了0，继续学习，还能进一步拉开不同类别的距离。

        一般的优化不会停止在局部最小点，以及保持在梯度最小；而机器学习是设计为在发生过拟合之前终止。并且终止时，仍然有较大的导数。

        举例：

        真实分类 $y=[1,0,1,0,1,0]$，预测分类$\hat y=[1,1,1,1,1,1]$

        理论上我们应该用如下零损失函数：

        $$J(\theta)=\frac 1m\sum_{i=0}^mL(y \neq \hat y)$$

        即：

        $$J(\theta)=\frac 16(0+1+0+1+0+1)=0.5$$

        我们目标是最小化$J(\theta)$，但此函数的梯度不连续，所以不可解。

        所以只能用代理损失函数即负对数似然：

        $$J(\theta)=-\frac 1m\sum_{i=0}^mL(ylog(\hat y))$$
 
    3. 批量算法和小批量算法

        机器学习和优化算法都是在训练集上完成的，优化一般是使用整个训练集或单个样本，而机器学习都是使用1个以上，但不是全部的样本进行训练称为随机方法。

        小批量的大小由以下因素决定：

        - 更大的批量会计算更精确的梯度估计，但回报却是小于线性的。

        - 极小批量通常难以充分利用多核架构。

        - 如果批量中的所有样本都可以并行处理，硬件设施是批量大小的限制因素。

        - 在某些硬件如GPU上用2的冥数作为批量大小可以获得更少的运行时间。一般都是32~256，16是针对大模型时使用。

        - 可能是小批量在学习中加入了噪声，所以有正则化的效果。小批量学习时需要较小的学习率保持稳定性。

        小批量需要是随机抽取的。

        可以采用并行的计算不同小批量的最小化更新

        小批量如果没有重复的样本都是遵循真实泛化误差，如果第二次遍历，是有偏的。但除非数据量很大，通常好多遍遍历数据集。虽然只有第一遍是无偏估计，但额外的遍历更新会由于减少训练误差得到足够的好处，以抵消带来的训练误差和样本误差之间的差距增加。

        随着数据集的规模迅速增长，很多样本只使用一次，甚至是不完整的使用训练集，这是最的考虑不是过拟合，而是欠拟合和计算效率。

1. 神经网络优化中的挑战

    1. 病态

        在优化凸函数时，最普遍存在的问题就是海森矩阵H的病态。病态问题一般被认为存在于神经网络训练中，病态体现在随机梯度下降会卡在某些情况。此时即使很小的更新步长也会导致代价函数增长。

        判断病态是监控$g^Tg$平方梯度范数和$g^THg$。$g^Tg$平方梯度范数不会显著减少，但$g^THg$会超过一个数量级，导致梯度没有减少，但学习会变得很慢，必需减少学习率。成功训练的神经网络，梯度会显著增加。

        可以用牛顿法来解决病态

    2. 局部极小值

        凸优化的一个突出特点就是为寻找一个局部极小点的问题，任何一个局部极小点都是全局最小点。非凸优化，如神经网络，可能出现多个局部极小值。

        除了权重空间的对称性，还有任意整流线性网络或maxout网络中，可以将传入的权重和偏置剧烈扩大和缩小a倍，导致模型不可辨认。

        如果局部极小值比全局最小点拥有更大的梯度，则会带来很大的隐患。

        目前猜测，对于足够大的神经网络，大部分局部极小值只有很小的梯度，不会造成问题。

        不要将所有的优化困难都归结于局部极小值。如果梯度的范数没有随训练时间缩小到一个微小的值，那么该问题就不是局部极小值问题。在高维空间，很难明确证明局部极小值是导致问题的原因，很多非局部极小值结构也具有很小的梯度。

    3. 高原、鞍点和其它平坦区域

        对于很多高维非凸函数而言，局部极小值事实上都远少于另一类梯度为0的点：鞍点。

        在低维空间，局部极小值普遍；在高维空间，则鞍点普遍。海森矩阵在局部极小值只有正特征值，在鞍点则同时有正负特征值。在低维，抛一次正值很容易；在n维同时n次抛正值很难。

        由于鞍点的附近的梯度都处于极小值，所以导致代价函数是平坦的，权重为零，无法进一步下降。

        梯度下降会逃离鞍点，但牛顿法的明确目标就是寻找梯度为零的点，会陷入鞍点。

        除了极小值和鞍点，还存在其他梯度为零的点，例如最大值、恒值、宽且平坦的区域等，这些区域梯度和海森矩阵都为零，这种退化问题是所有数值优化问题的主要问题。

    4. 悬崖和梯度爆照

        多层神经网络存在象悬崖一样的斜率较大区域，通常梯度更新会完全跳过这些区域。

        高的梯度会让参数更新过大，因此可以采用梯度截断来避免这个问题。

        当梯度下降算法要求更新一大步时，启发式梯度截断会干涉来减少步长，这样就不会直接跳过悬崖区域。

    5. 长期依赖

        当网络极深时，会造成模型丧失了学习到之前信息的能力，让优化非常困难。这个问题不仅出现在前馈网络，还存在于循环网络。

        网络很深时，相当于W会连续相乘，这样很容易造成梯度消失或梯度爆炸问题，从而导致学习不稳定。

        这个问题在循环网络更为严重，循环网络使用相同的矩阵W，相比较前馈网络的W基本都不同。所以采用前馈网络可以很大程度避免出现梯度消失或梯度爆炸的问题。

    6. 非精确梯度

        因为神经网络都是采样或部分数据集训练，所以梯度非精确，只能近似梯度。

        目前神经网络的优化都有考虑到这个问题，可以采用选择比真实损失函数更容易估计的代理损失函数来避免这个问题。

    7. 局部和全局结构间的弱对应

        大部分的优化研究的难点在于训练是否找到了全局最低点、局部极小点或鞍点。但神经网络不会到达任何一个临界点，甚至这些点有可能不存在。例如负对数，只会无限收敛于零。这样造成一个问题，如果$f(x;\theta)$能够正确的预测所有训练集的目标y，则学习算法会无限的增加$\theta$

        未来的优化主要集中在进一步探索影响学习轨迹长度和更好的表征训练过程的结果。

        由于计算全局信息的计算量太大，目前只能计算小范围的梯度信息，导致局部信息不能提供任何指导，所以当前主流的解决思路还是建议在传统优化算法上，研究如何选择更佳的初始化点，让我们遵循局部下降便能合理的直接达到某个解。

    8. 优化的理论限制

        我们为神经网络的任何优化算法都有性能限制，通常这些结果不影响实际应用。

        有些理论说明无解，但实际随着神经网络的增加可以找到可接受的解。所以对优化算法是否能完成此目标进行理论分析很困难，我们只是关注研究优化算法更现实的上界目标。

1. 基本算法

    1. 随机梯度下降

        SGD是应用最多的优化算法。

        > 定义学习率 $\epsilon$
        > 
        > 定义初始参数 $\theta$
        >
        > while 停止准则未满足：   
        >
        >>   从训练集中选择m个小批量x和对应的y 
        >>
        >>   计算梯度估计 $g=g+\frac 1m\nabla_\theta \sum_iL(f(x_i;\theta),y_i)$  
        >>
        >>   应用更新 $\theta=\theta-\epsilon*g$

        SGD算法的关键是学习率，实践中要将学习率随时间递减。

        学习率可以通过实验和误差选取，通常是检查学习曲线。

        线性衰减学习率：

        $$\epsilon_k=(1-a)\epsilon_0 +a\epsilon_t$$

        表示目标迭代的总步数t，k是一次迭代中的步数。
        
        a=k/t，当前步数和总步数比例，$\epsilon_0$为初始化学习速率，$\epsilon_t$ 为最终的学习速率，通常是初始学习率的1%。

        学习率设置的太大，会剧烈震荡，太小，会过程缓慢。
        
        SDG的重要特性是每一步的更新的计算时间不依赖训练样本数目的多寡，有可能在没有学习完毕所有样本时，就达到最终测试集误差范围内。

        有人认为不值得探寻收敛更快的优化算法，更快的收敛意味对应过拟合。

    1. 动量

        动量算法引入了变量v充当速度，用于加速学习，处理高曲率，小但一致的梯度或带噪声的梯度。速度被设置为负梯度的指数衰减平均。

        $$v = av-\epsilon\nabla_\theta(\frac 1m\sum_{i=1}^mL(f(x_i;\theta),y_i))$$

        $$\theta=\theta+v$$

        > 定义学习率 $\epsilon$，动量参数 $a$
        > 
        > 定义初始参数 $\theta$，初始速度 $v$
        >
        > while 停止准则未满足：   
        >
        >>   从训练集中选择m个小批量x和对应的y 
        >>
        >>   计算梯度估计 $g=g+\frac 1m\nabla_\theta \sum_iL(f(x_i;\theta),y_i)$  
        >>
        >>   计算速度更新 $v=av-\epsilon g$
        >>
        >>   应用更新 $\theta=\theta+v$

        在实践中，a的取值一般为0.5、0.9和0.99.






目标是寻找神经网络上的一组参数$\theta$，它能显著的降低代价函数$J(\theta)$。该代价函数包括性能评估和正则化项。

1. 学习和纯优化有什么不同

    用于深度模型的优化和传统不同，深度模型不会直接去更新我们关注的性能度量P，只是间接的优化P，通过降低代价函数$J(theta)$来提高P。纯优化是直接最小化目标J本身。

    通常代价函数写为训练集上的平均：

    $$J(\theta)=\mathbb E_{(x,y)\sim\hat p_{data}}L(f(x;\theta),y)$$

    $L$是每个样本的损失函数，$f(x;\theta)$是输入x时所预测的输出，$\hat p_{data}$ 是经验分布，$y$是目标输出。 通常我们更希望的最小化全部的数据分布$p_{data}$，而不是训练集上的经验分布$\hat p_{data}$。

    1. 经验风险最小化

        
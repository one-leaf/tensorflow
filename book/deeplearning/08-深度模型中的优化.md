目标是寻找神经网络上的一组参数$\theta$，它能显著的降低代价函数$J(\theta)$。该代价函数包括性能评估和正则化项。

1. 学习和纯优化有什么不同

    用于深度模型的优化和传统不同，深度模型不会直接去更新我们关注的性能度量P，只是间接的优化P，通过降低代价函数$J(theta)$来提高P。纯优化是直接最小化目标J本身。

    通常代价函数写为训练集上的平均：

    $$J(\theta)=\mathbb E_{(x,y)\sim\hat p_{data}}L(f(x;\theta),y)$$

    $L$是每个样本的损失函数，$f(x;\theta)$是输入x时所预测的输出，$\hat p_{data}$ 是经验分布，$y$是目标输出。 通常我们更希望的最小化全部的数据分布$p_{data}$，而不是训练集上的经验分布$\hat p_{data}$。

    1. 经验风险最小化

        目标是降低上面所示的期望泛化误差，这个数据量被称为风险。将机器学习问题转化回一个优化问题的最简单办法是最小化训练集上的期望损失。我们叫最小化经验风险。这种训练过程叫经验风险最小化，即：

        $$J(\theta)=\mathbb E_{(x,y)\sim\hat p_{data}}L(f(x;\theta),y)=\frac 1m\sum_{i=1}^mL(f(x_i;\theta),y_i)$$

        m是样本的个数，最小化经验风险很容易过拟合。最有效的还是算法还是基于梯度下降的。深度学习中很少使用经验风险最小化。

    2. 代理损失函数和提前终止

        我们真正关心的损失函数并不能被高效的优化，这种情况下，我们通常会优化代理损失函数。

        例如分类[0,1]的损失是不可解的，我们通常使用负对数似然来代替[0,1]。而且这个效果会比直接学习[0,1]更好，因为即使到了0，继续学习，还能进一步拉开不同类别的距离。

        一般的优化不会停止在局部最小点，以及保持在梯度最小；而机器学习是设计为在发生过拟合之前终止。并且终止时，仍然有较大的导数。

        举例：

        真实分类 $y=[1,0,1,0,1,0]$，预测分类$\hat y=[1,1,1,1,1,1]$

        理论上我们应该用如下零损失函数：

        $$J(\theta)=\frac 1m\sum_{i=0}^mL(y \neq \hat y)$$

        即：

        $$J(\theta)=\frac 16(0+1+0+1+0+1)=0.5$$

        我们目标是最小化$J(\theta)$，但此函数的梯度不连续，所以不可解。

        所以只能用代理损失函数即负对数似然：

        $$J(\theta)=-\frac 1m\sum_{i=0}^mL(ylog(\hat y))$$
 
    3. 批量算法和小批量算法

        机器学习和优化算法都是在训练集上完成的，优化一般是使用整个训练集或单个样本，而机器学习都是使用1个以上，但不是全部的样本进行训练称为随机方法。

        小批量的大小由以下因素决定：

        - 更大的批量会计算更精确的梯度估计，但回报却是小于线性的。

        - 极小批量通常难以充分利用多核架构。

        - 如果批量中的所有样本都可以并行处理，硬件设施是批量大小的限制因素。

        - 在某些硬件如GPU上用2的冥数作为批量大小可以获得更少的运行时间。一般都是32~256，16是针对大模型时使用。

        - 可能是小批量在学习中加入了噪声，所以有正则化的效果。小批量学习时需要较小的学习率保持稳定性。

        小批量需要是随机抽取的。

        可以采用并行的计算不同小批量的最小化更新

        小批量如果没有重复的样本都是遵循真实泛化误差，如果第二次遍历，是有偏的。但除非数据量很大，通常好多遍遍历数据集。虽然只有第一遍是无偏估计，但额外的遍历更新会由于减少训练误差得到足够的好处，以抵消带来的训练误差和样本误差之间的差距增加。

        随着数据集的规模迅速增长，很多样本只使用一次，甚至是不完整的使用训练集，这是最的考虑不是过拟合，而是欠拟合和计算效率。

1. 神经网络优化中的挑战

    1. 病态

        在优化凸函数时，最普遍存在的问题就是海森矩阵H的病态。病态问题一般被认为存在于神经网络训练中，病态体现在随机梯度下降会卡在某些情况。此时即使很小的更新步长也会导致代价函数增长。

        判断病态是监控$g^Tg$平方梯度范数和$g^THg$。$g^Tg$平方梯度范数不会显著减少，但$g^THg$会超过一个数量级，导致梯度没有减少，但学习会变得很慢，必需减少学习率。成功训练的神经网络，梯度会显著增加。

        可以用牛顿法来解决病态

    2. 局部极小值

        凸优化的一个突出特点就是为寻找一个局部极小点的问题，任何一个局部极小点都是全局最小点。非凸优化，如神经网络，可能出现多个局部极小值。

        除了权重空间的对称性，还有任意整流线性网络或maxout网络中，可以将传入的权重和偏置剧烈扩大和缩小a倍，导致模型不可辨认。

        如果局部极小值比全局最小点拥有更大的梯度，则会带来很大的隐患。

        目前猜测，对于足够大的神经网络，大部分局部极小值只有很小的梯度，不会造成问题。

        不要将所有的优化困难都归结于局部极小值。如果梯度的范数没有随训练时间缩小到一个微小的值，那么该问题就不是局部极小值问题。在高维空间，很难明确证明局部极小值是导致问题的原因，很多非局部极小值结构也具有很小的梯度。

    3. 高原、鞍点和其它平坦区域

        对于很多高维非凸函数而言，局部极小值事实上都远少于另一类梯度为0的点：鞍点。

        在低维空间，局部极小值普遍；在高维空间，则鞍点普遍。海森矩阵在局部极小值只有正特征值，在鞍点则同时有正负特征值。在低维，抛一次正值很容易；在n维同时n次抛正值很难。

        由于鞍点的附近的梯度都处于极小值，所以导致代价函数是平坦的，权重为零，无法进一步下降。

        梯度下降会逃离鞍点，但牛顿法的明确目标就是寻找梯度为零的点，会陷入鞍点。

        除了极小值和鞍点，还存在其他梯度为零的点，例如最大值、恒值、宽且平坦的区域等，这些区域梯度和海森矩阵都为零，这种退化问题是所有数值优化问题的主要问题。

    4. 悬崖和梯度爆照

        多层神经网络存在象悬崖一样的斜率较大区域，通常梯度更新会完全跳过这些区域。

        高的梯度会让参数更新过大，因此可以采用梯度截断来避免这个问题。

        当梯度下降算法要求更新一大步时，启发式梯度截断会干涉来减少步长，这样就不会直接跳过悬崖区域。

    5. 长期依赖

        当网络极深时，会造成模型丧失了学习到之前信息的能力，让优化非常困难。这个问题不仅出现在前馈网络，还存在于循环网络。

        网络很深时，相当于W会连续相乘，这样很容易造成梯度消失或梯度爆炸问题，从而导致学习不稳定。

        这个问题在循环网络更为严重，循环网络使用相同的矩阵W，相比较前馈网络的W基本都不同。所以采用前馈网络可以很大程度避免出现梯度消失或梯度爆炸的问题。

    6. 非精确梯度

        因为神经网络都是采样或部分数据集训练，所以梯度非精确，只能近似梯度。

        目前神经网络的优化都有考虑到这个问题，可以采用选择比真实损失函数更容易估计的代理损失函数来避免这个问题。

    7. 局部和全局结构间的弱对应

        大部分的优化研究的难点在于训练是否找到了全局最低点、局部极小点或鞍点。但神经网络不会到达任何一个临界点，甚至这些点有可能不存在。例如负对数，只会无限收敛于零。这样造成一个问题，如果$f(x;\theta)$能够正确的预测所有训练集的目标y，则学习算法会无限的增加$\theta$

        未来的优化主要集中在进一步探索影响学习轨迹长度和更好的表征训练过程的结果。

        由于计算全局信息的计算量太大，目前只能计算小范围的梯度信息，导致局部信息不能提供任何指导，所以当前主流的解决思路还是建议在传统优化算法上，研究如何选择更佳的初始化点，让我们遵循局部下降便能合理的直接达到某个解。

    8. 优化的理论限制

        我们为神经网络的任何优化算法都有性能限制，通常这些结果不影响实际应用。

        有些理论说明无解，但实际随着神经网络的增加可以找到可接受的解。所以对优化算法是否能完成此目标进行理论分析很困难，我们只是关注研究优化算法更现实的上界目标。

1. 基本算法

    1. 随机梯度下降

        SGD是应用最多的优化算法。

        > 定义学习率 $\epsilon$
        > 
        > 定义初始参数 $\theta$
        >
        > while 停止准则未满足：   
        >
        >>   从训练集中选择m个小批量x和对应的y 
        >>
        >>   计算梯度估计 $g=g+\frac 1m\nabla_\theta \sum_iL(f(x_i;\theta),y_i)$  
        >>
        >>   应用更新 $\theta=\theta-\epsilon*g$

        SGD算法的关键是学习率，实践中要将学习率随时间递减。

        学习率可以通过实验和误差选取，通常是检查学习曲线。

        线性衰减学习率：

        $$\epsilon_k=(1-a)\epsilon_0 +a\epsilon_t$$

        表示目标迭代的总步数t，k是一次迭代中的步数。
        
        a=k/t，当前步数和总步数比例，$\epsilon_0$为初始化学习速率，$\epsilon_t$ 为最终的学习速率，通常是初始学习率的1%。

        学习率设置的太大，会剧烈震荡，太小，会过程缓慢。
        
        SDG的重要特性是每一步的更新的计算时间不依赖训练样本数目的多寡，有可能在没有学习完毕所有样本时，就达到最终测试集误差范围内。

        有人认为不值得探寻收敛更快的优化算法，更快的收敛意味对应过拟合。

    1. 动量

        动量算法引入了变量v充当速度，用于加速学习，处理高曲率，小但一致的梯度或带噪声的梯度。速度被设置为负梯度的指数衰减平均。

        $$v = av-\epsilon\nabla_\theta(\frac 1m\sum_{i=1}^mL(f(x_i;\theta),y_i))$$

        $$\theta=\theta+v$$

        > 定义学习率 $\epsilon$，动量参数 $a$
        > 
        > 定义初始参数 $\theta$，初始速度 $v$
        >
        > while 停止准则未满足：   
        >
        >>   从训练集中选择m个小批量x和对应的y 
        >>
        >>   计算梯度估计 $g=\frac 1m\nabla_\theta \sum_iL(f(x_i;\theta),y_i)$  
        >>
        >>   计算速度更新 $v=av-\epsilon g$
        >>
        >>   应用更新 $\theta=\theta+v$

        在实践中，a的取值一般为0.5、0.9和0.99.

    1. Nesterov 动量

        和上面的仅仅为梯度的计算不同，通过引入临时参数，将梯度的计算在施加当前速度之后：

        $$v = av-\epsilon\nabla_\theta(\frac 1m\sum_{i=1}^mL(f(x_i;\theta+av),y_i))$$

        $$\theta=\theta+v$$

        > 定义学习率 $\epsilon$，动量参数 $a$
        > 
        > 定义初始参数 $\theta$，初始速度 $v$
        >
        > while 停止准则未满足：   
        >
        >>   从训练集中选择m个小批量x和对应的y 
        >>
        >>  应用临时更新：$\hat \theta=\theta+av$
        >>
        >>   计算梯度估计 $g=\frac 1m\nabla_{\hat \theta} \sum_iL(f(x_i;\hat \theta),y_i)$  
        >>
        >>   计算速度更新 $v=av-\epsilon g$
        >>
        >>   应用更新 $\theta=\theta+v$

1. 参数初始化策略

    初始参数直接影响到学习收敛和泛化误差。初始参数的目的是在不同单元间破坏对称性。

    目前大部分都是初始化参数权重为高斯分布或均匀分布，不过对比没有详细的研究。

    更大的初始化权重具有更强的破坏对称性的作用，有助于避免冗余单元；但会在前向传播或反向传播中产生爆炸的值；在RNN中会导致混沌，对输入的很小扰动非常敏感，导致确定性前向传播表现随机。也就是梯度爆炸问题。梯度爆炸可以通过梯度裁剪来缓解，但大的初始化权重还使激活函数处于饱和区域，导致梯度消失。

    在设置初始化权重，优化和正则化的观点相反，优化要大的初始化权重以便更好的传播信息，不会丢失信息；正则化要求权重减小，因此最好将权重初始化到0附近。

    对于权重的看法：

    - 对于m个输入和n个输出的全连接层，建议采用标准初始化：

    $$W_{i,j}\in U(-\sqrt\frac{6}{m+n},\sqrt\frac{6}{m+n})$$

    - 推荐初始化为随机正交矩阵，仔细为每一层挑选非线性缩放或增益因子g

    - 如果设置所有的权重都是同样的标准差，当某些层很大时，会导致每个权重变的很小，所以提出了稀疏初始化。每个单元初始化为有k个非零权重。系数初始化有助于实现单元之间的多样性，但也会导致某些参数加了很强的先验。

    - 如果资源允许，针对每层的范围独立设置超参，例如范围、采用密集或稀疏等类型。可以通过观察小批量数据的激活情况或梯度的幅度或标准差等来确定。

    对于偏置的看法：

    - 大多数情况设置为零是没有问题的

    - 如果偏置作为输出单元，可以将权重设置小，偏置使用softmax(b)=c来设置b，有助于偏置匹配到x的边缘分布。

    - 有时为了防止relu饱和，因此将relu隐藏单元的偏置设置为0.1。

    - LSTM中将遗忘门的偏置设置为1，以便控制其他单元是否参与到等式中。

    其他：

    可以将参数设置为方差或精确度参数。例如一下模型，带条件方差估计的线性回归：

    $$p(y|x)=N(y|w^Tx+b,1/\beta)$$

    其中$\beta$就是精确度参数。通常可以将这个值初始化为1.

    还有一种先用无监督学习训练相同的数据集，然后用这组参数作为监督学习的初始化参数初始值。这样也能得到一个比随机初始化具有更快收敛率的初始值和更好的泛化误差。

1. 自适应学习率算法

    学习率对模型的影响显著，难设置。

    Delta-bar-delta 算法是早期的自适应学习率算法，基于：如果损失对于某个给定模型参数的偏导保持相同的符号，学习率就应该增加，如果该参数的偏导变化了符号，学习率就应该减小，但只能用于全批量优化。

    1. AdaGrad

        缩放每个参数反比于所有梯度历史平方总和的平方根。损失大偏导，学习率就下降大，小偏导，学习率下降小。

        经验发现AdaGrad会导致有效学习率过早或过量的减小。适用于部分模型。

        > 定义学习率 $\epsilon$
        > 
        > 定义初始参数 $\theta$
        >
        > 定义小常数，稳定数值用 $\delta$ 一般设置为$10^{-7}$
        >
        > 定义初始化累积梯度 $r=0$
        >
        > while 停止准则未满足：   
        >
        >>   从训练集中选择m个小批量x和对应的y 
        >>
        >>   计算梯度估计 $g=\frac 1m\nabla_\theta \sum_iL(f(x_i;\theta),y_i)$  
        >>
        >>   累积平方梯度 $r=r+g\odot g$
        >>
        >>   计算更新 $\Delta \theta=\frac {\epsilon}{\delta+\sqrt r}\odot g$
        >>
        >>   应用更新 $\theta=\theta+\Delta \theta$

    1. RMSProp 

        由AdaGrad修改来的，改变梯度累积为指数加权移动平均，主要改进在非凸优化下的效果。

        > 定义学习率 $\epsilon$， 衰减速率 $p$
        > 
        > 定义初始参数 $\theta$
        >
        > 定义小常数，稳定数值用 $\delta$ 一般设置为$10^{-6}$
        >
        > 定义初始化累积梯度 $r=0$
        >
        > while 停止准则未满足：   
        >
        >>   从训练集中选择m个小批量x和对应的y 
        >>
        >>   计算梯度估计 $g=\frac 1m\nabla_\theta \sum_iL(f(x_i;\theta),y_i)$  
        >>
        >>   累积平方梯度 $r=pr+(1-p)g\odot g$
        >>
        >>   计算更新 $\Delta \theta=\frac {\epsilon}{\delta+\sqrt r}\odot g$
        >>
        >>   应用更新 $\theta=\theta+\Delta \theta$

        也可以和动量相结合，原理同上。

        目前此方法比较常用。

    1. Adam

        结合了RMSProp和动量模型。

        > 定义学习率 $\epsilon$， 建议0.001
        >
        > 定义矩估计一阶和二阶指数衰减速率，起始在[0,1]区间内，建议$p_1=0.9, p_2=0.999$
        > 
        > 定义初始参数 $\theta$
        >
        > 定义小常数，稳定数值用 $\delta$ 一般设置为$10^{-8}$
        >
        > 初始化一阶和二阶矩变量 $s=0,r=0$ 初始化时间步 $t=0$
        >
        > while 停止准则未满足：   
        >
        >>   从训练集中选择m个小批量x和对应的y 
        >>
        >>   计算梯度估计 $g=\frac 1m\nabla_\theta \sum_iL(f(x_i;\theta),y_i)$  
        >>
        >>  $t=t+1$
        >>
        >>  更新有偏一阶矩估计 $s=p_1s+(1-p_1)g$
        >>
        >>  更新有偏二阶矩估计 $r=p_2s+(1-p_2)g\odot g$
        >>
        >>  修正一阶矩的偏差 $\hat s=\frac {s}{1-p_1^t}$
        >>
        >>  修正二阶矩的偏差 $\hat r=\frac {r}{1-p_2^t}$
        >>
        >>   计算更新 $\Delta \theta=-\epsilon \frac {\hat s}{\delta+\sqrt {\hat r}}$
        >>
        >>   应用更新 $\theta=\theta+\Delta \theta$        

    1. 选择正确的优化算法

        没有绝对的好坏，看熟悉程度。

        经验：

        - 对于稀疏数据特征，目前最好的是 Adam

        - 纯粹的SGD可以收敛到最小值点，但花费的时间长，容易陷入在局部最小点。

        [各优化算法代码对比](./code/08-1.py)

1. 二阶近似方法

    1. 牛顿法

        最广泛的二阶方法就是牛顿法。梯度下降是一阶方法的，所以牛顿法更快，通俗地讲，找一条最短的路径走到最底部，梯度下降法每次只从当前所处位置选梯度最大的方向走一步，牛顿法在选择方向时，不仅会考虑梯度是否够大，还会考虑走了一步之后，梯度是否会变得更大。

        泰勒级数为：

        $$g(x)=1+x+\frac {x^2}{2!}+\frac {x^3}{3!}+...$$

        函数f(x)在a处的多项式展开，即泰勒展开式为：

        $$f(x)=\sum_{n=0}^N\frac{f^{(n)}(a)}{n!}(x-a)^n+R_n(x)$$
        
        $R_n(x)$是$(x-a)^n$的高阶无穷小，省略掉。

        牛顿法基于二阶泰勒级数展开在某$\theta_0$附近来近似$J(\theta)$的优化方法：

        $$J(\theta)\approx J(\theta_0)+(\theta-\theta_0)^T\nabla_{\theta}J(\theta_0)+\frac 12(\theta-\theta_0)^TH(\theta-\theta_0)$$

        其中$H$是$J$相对于$\theta$的海森矩阵在$\theta_0$处的估计。解得：

        $$\hat \theta=\theta_0-H^{-1}\nabla_{\theta}J(\theta_0)$$

        因此只要H保持正定，即：$(\theta-\theta_0)^TH(\theta-\theta_0)>0$，牛顿法就可以迭代应用到极小值。

        算法如下：

        > 定义初始参数 $\theta_0$
        >
        > while 停止准则未满足：   
        >
        >>  从训练集中选择m个小批量x和对应的y 
        >>
        >>  计算梯度 $g=\frac 1m\nabla_\theta \sum_iL(f(x_i;\theta),y_i)$  
        >>
        >>  计算海森矩阵 $H=\frac 1m\nabla_\theta^2\sum_iL(f(x_i;\theta),y_i)$
        >>
        >>  计算海森矩阵的逆：$H^{-1}$
        >>
        >>   计算更新 $\Delta \theta=-H^{-1}g$
        >>
        >>   应用更新 $\theta=\theta+\Delta \theta$   

        注：逆矩阵是一个判断相似性的工具。逆矩阵$H^{-1}$与列向量g相乘后，将得到列向量$\Delta \theta$，$\Delta \theta$的第i个分量表示g与$H$的第i个列向量的相似度。

        这样在靠近鞍点的时候，H的特征值为负时，牛顿法会导致更新朝错误的方向，这种情况时有正则化海森矩阵来避免。常用的正则化策略是在海森矩阵对角线上增加常数a，即：

        $$\hat \theta=\theta_0-[H(f(\theta_0))+aI]^{-1}\nabla_\theta f(\theta_0)$$

        这样只要H的负特征值接近于零，效果也不错。当曲率更大时，增加a，以抵消负特征值，副作用是导致牛顿法的步长比梯度下降会小。

        牛顿法的问题难点在于计算海森矩阵的逆，这里计算量比较大。

    1. 共轭梯度

        为了减少海森矩阵求逆的大计算量，共轭梯度是一种通过迭代下降的共轭方向计算方法。

        在共轭梯度法中，寻求一个和先前搜索方向共轭的搜索方向，这样不会撤销该方向上的进展：

        $$d_t=\nabla_\theta J(\theta)+\beta_td_{t-1}$$

        其中 $\beta_t$ 有两种计算方法：

        $$\beta_t=\frac {\nabla_\theta J(\theta_t)^T\nabla_\theta J(\theta_t)}{\nabla_\theta J(\theta_{t-1})^T\nabla_\theta J(\theta_{t-1})}$$

        或

        $$\beta_t=\frac {(\nabla_\theta J(\theta_t)-\nabla_\theta J(\theta_{t-1}))^T\nabla_\theta J(\theta_t)}{\nabla_\theta J(\theta_{t-1})^T\nabla_\theta J(\theta_{t-1})}$$

        完整算法如下：

        > 定义初始参数 $\theta_0$
        >
        > 定义初始参数 $p_0=0,g_0=0,t=1$
        >
        > while 停止准则未满足：   
        >
        >>  从训练集中选择m个小批量x和对应的y 
        >>
        >>  初始化梯度g_t=0
        >>
        >>  计算梯度 $g_t=\frac 1m\nabla_\theta \sum_iL(f(x_i;\theta),y_i)$  
        >>
        >>  计算 $\beta_t=\frac {(g_t-g_{t-1})^Tg_t}{g_{t-1}^Tg_{t-1}}$
        >>
        >>  计算搜索方向：$p_t=-g_t+\beta_tp_{t-1}$
        >>
        >>  执行线搜索寻找 $\hat \epsilon=argmin_\epsilon\frac 1m\sum_{i=1}^mL(f(x_i;\theta_t+\epsilon p_t),y_i)$
        >>
        >>  应用更新 $\theta_{t+1}=\theta_t+\hat\epsilon p_t$  
        >>
        >>  t=t+1
       
    1. BFGS

        也是近似牛顿法，减少了计算量。

        特点是使用矩阵$M_t$来近似逆。

        $$p_t=M_tg_t$$
        
        $$\theta_{t+1}=\theta_t+\hat\epsilon p_t$$

        需要用保存M来存储海森的逆矩阵，不适合大规模参数的模型。

        L-BFGS ，存储受限的BFGS算法，只保留用于更新M的向量，不完整存储M。

    1. [参考网址](https://blog.csdn.net/golden1314521/article/details/46225289)

1. 优化策略和元算法

    1. 批标准化

        批标准化是神经网络中最激动人心的创新之一，是自适应重参数的方法，为了解决训练非常深的模型。

        批标准化将H层替换为H'：

        $$H_{i,j}'=\frac {H_{i,j}-\mu_j}{\sigma_j}$$

        $\mu$是矩阵H每一行单个单元的均值向量，$\sigma$是矩阵H每一行每个单元的标准差向量。

        在训练阶段：

        $$\mu=\frac 1m\sum_iH_i,:$$

        $$\sigma=\sqrt {\delta+\frac 1m\sum_i(H-\mu)^2_i}$$

        $\delta$ 是一个很小的正数例如10e-8，用来避免$\sigma$为0，造成除法错误。$\mu$和$\sigma$是动态计算获得，这就意味，不再需要增加代价函数项来增加惩罚或在梯度下降之后重新修正标准化单元统计量。这种每次训练都动态定义标准化比用代价函数更加彻底，也避免了后面重算的运算量。在测试阶段，$\mu$和$\sigma$为训练阶段所收集的均值。

        假设x是一个高斯分布，则h也是一个高斯分布，因为h是x的线性变换，所以失去了0均值和单位方差，而批标准化，则恢复h为0均值和单位方差，这样就可以保持整个网络简单，直到输出都是0均值和单位方差。

        批标准化仅仅标准化每个单元的均值和方差，以稳定化学习，但允许单元和单个单元的非线性统计量之间的关系发生变化。

        标准化一个单元的均值和标准差会降低该单元的神经网络表达能力，通常将H替换为$\gamma H'+\beta$,这样新的两个参数允许调整均值和标准差，相比旧的参数带来了不同的学习动态。

        批标准化应该放到激活函数前，$wx+b$之后。这样下一层的输入在非线性激活函数之后，更符合非高斯，而不是线性操作。

        [实例代码](./code/08-2.py)

    1. 坐标下降

        某些时候，将一个问题分解成几个部分，依次分别处理，可以更快的解决问题。，例如我们对一个单一变量x1最小化f(x)，然后在对另外一个变量x2最小化f(x),等等，反复循环所有的变量，就可以达到局部最小值。这种做法就称为坐标下降。更多时候是针对一个子集进行。

        但一个变量很大程度的影响到另外一个变量的最优值时，例如:$f(x)=(x_1-x_2)^2+a(x_1^2+x_2^2)$，a是正值常数，坐标下降不是一个好办法。因为第一项，鼓励两个变量相同，第二项，鼓励两个变量接近于零，这两个变量太相关。这种情况可以考虑使用牛顿法，这是一个正定二次问题。

    1. Polyak 平均

        就是平均优化算法在参数空间访问的轨迹中的点。例如：在梯度下降中，访问了$\theta_1,\cdots,\theta_t$,则$\hat \theta_t=\frac 1t\sum_{i=1}^t\theta_i$。
        
        对于神经网络，用的多的是指数衰减计算平均值：

        $$\hat \theta_t=a\hat\theta_{t-1}+(1-a)\theta_t$$

    1. 监督预训练

        在直接训练目标模型求解目标问题之前，训练简单模型求解简化问题的方法统称为预训练。

        贪心算法将问题分解为许多部分，然后独立的每个部分求最优值，虽然合起来不能保证得到一个最佳完整解，但比求解联合解的算法高效很多，即使解不是最好的，大部分都是可以接受的。

        预训练算法特别是贪心预训练算法在深度学习普遍使用，称为贪心监督预训练。

        迁移学习也使用预训练算法。另外就是FitNets，先训练一个足够宽和低的网络，然后将这个网络成为第二个网络（指定为学生）的老师。学生的网络更深更窄，通常SGD训练困难。训练学生网络，不仅需要预测原任务的输出，还需要预测教师网络中间层的值，这样就可以让网络训练变的容易。（主要窄和深的网络泛化比较好，加上参数少，计算代价小）

        基于中间层的提示是有助于训练很难训练的方法之一，其他的优化方法也能解决这个问题。

        [参考代码](./code/08-3.py)

    


        
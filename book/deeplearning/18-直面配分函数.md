一般概率模型都是由一个未归一化的概率分布 $\hat p(x,\theta)$ 定义，我们需要除以配分函数$Z(\theta)$ 来归一化$\hat p$，以获得一个有效的概率分布。

$$p(x;\theta)=\frac {1}{Z(\theta)}\hat p(x;\theta)$$

配分函数是未归一化概率所有状态的积分（连续变量）或求和（离散变量）。

$$Z=\int \hat p(x)dx$$

或

$$Z=\sum \hat p(x)$$


对于很多模型，以上积分或求和都难以计算。

1. 对数似然梯度

    通过最大似然学习无向模型特别困难的原因在于配分函数依赖于参数。对数似然相对于参数的梯度，具有一项对应于配分函数的梯度：

    $$\nabla_\theta \log p(x;\theta)=\nabla_\theta \log \hat p(x;\theta) - \nabla_\theta \log Z(\theta) $$

    这是机器学习中的非常著名的正相和负相的分解。一般正相好计算，但负相的计算比较困难，分析如下：

    $$\nabla_\theta \log Z=\frac {\nabla_\theta Z}{Z}=\frac {\nabla_\theta \sum_x \hat p (x)}{Z}=\frac {\sum_x \nabla_\theta \hat p (x)}{Z}$$

    为了保证所有的p(x)>0，用指数代替:$\hat p(x)=exp (\log \hat p(x))$

    $$\frac {\sum_x \nabla_\theta \hat p (x)}{Z}=\frac {\sum_x \nabla_\theta exp (\log \hat p(x))}{Z}$$

    $$=\frac {\sum_x  exp (\log \hat p(x)) \nabla_\theta \log \hat p(x)}{Z}$$

    $$=\frac {\sum_x  \hat p(x) \nabla_\theta \log \hat p(x)}{Z}$$

    $$=\sum_x  p(x) \nabla_\theta \log \hat p(x)$$

    $$=\mathbb E _{x \sim p(x)}  \nabla_\theta \log \hat p(x)$$

    上面是用离散变量的推导，用连续变量也可以推导出同样的结果：

    $$\nabla_\theta \log Z=\mathbb E _{x \sim p(x)}  \nabla_\theta \log \hat p(x)$$

    这个等式是各种蒙特卡罗方法近似最大化似然的基础。在正相中，增大从数据中采样获得 $\log \hat p(x)$ ， 在负相中通过降低从模型分布中采样的 $\log \hat p(x)$ 来降低配分函数。

    这个就意味着，当数据分布和模型分布相等时，正相推高数据点和负相压低数据点的机会相等，此时，不再有任何期望上的梯度，训练也停止。

1. 随机最大似然和对比散度

    对于 $\nabla_\theta \log Z$ 等式有个朴素的解决方案是，每次需要计算梯度时，磨合随机初始化的一组马尔可夫链。当使用随机梯度下降进行学习时，需要每次梯度中计算马尔可夫链，这样计算的代价太大，虽然在实际中是不可行的，但这个过程是其他近似算法的基础。

    我们可以将最大似然的的MCMC方法，看作两种力的平衡，一种是拉高数据出现的模型分布，一种是拉低模型采样出现的模型分布。这两种力分别对应$\log \hat p$和$\log Z$。

    因为负相涉及从模型分布中抽样，所以可以认为它在找模型中信任度很高的点。因为负相减少了这些点的概率，它们一般认为被代表了模型不正确的信念，在文献中通常称为“幻觉”或“幻想粒子”，实际上负相也被作为人类做梦的可能解释。意思是，醒时大脑会遵循$\log \hat p$的梯度，而睡觉时会遵循$\log \hat p$的负梯度最小化$\log Z$。

    一种代价比较低的优化过程：

    >  while 不收敛 do 
    >
    >>  从训练集中采样包含 m 个样本 ${x_1,...,x_m}$ 的小批量
    >
    >>  $g \leftarrow \frac{1}{m} \sum _{i=1}^m \nabla_\theta \log \hat p(x_i;\theta)$ //计算梯度
    >
    >>  for i = 1 to m do
    >>
    >>>  $\hat x_i \leftarrow x_i$ //归一化数据，如果不做方差会偏大，导致训练困难
    >>>
    >> end for
    >
    >> for i = 1 to k do
    >>
    >>> for j = 1 to m do
    >>>
    >>>> $\hat x_j \leftarrow gibbs\_update(\hat x_j)$  //gibbs 采样
    >>>
    >>> end for
    >>>
    >> end for
    >
    >> $g \leftarrow g - \frac{1}{m} \sum _{i=1}^m \nabla_\theta \log \hat p(\hat x_i;\theta)$ //重新计算梯度
    >>
    >> $\theta \leftarrow \theta + \epsilon g$ //更新参数
    >
    > end while

    进行 k 个Gibbs步骤的CD-k算法，在每一步骤中都重新初始化马尔可夫链，这样的计算代价比较小。最初数据的分布和模型分布并不一致，所以负相是不准确的，但正相可以增加数据的模型概率，运行一段时间后，模型会接近数据分布，并且负相也会准确。

1. 伪似然

    因为无向模型很容易计算概率的比率则不需要处理配分函数，这是，配分函数同时在分子和分母，互相抵消了：

    $$\frac {p(x)}{p(y)}=\frac {\frac {1}{Z}\hat p(x)}{\frac {1}{Z}\hat p(y)}=\frac {\hat p(x)}{\hat p(y)}$$

    伪似然正是基于条件概率，可以采样这种基于比率的形式，因此可以不用计算配分函数。

    $$p(a|b)=\frac {p(a,b)}{p(b)}=\frac {p(a,b)}{\sum _{a,c}p(a,b,c)}=\frac {\hat p(a,b)}{\sum _{a,c}\hat p(a,b,c)}$$

    困难在于为了计算对数似然，需要计算边缘概率，利用概率的链式法则展开：

    $$\log p(x)=\log p(x_1)+\log p(x_2|x_1)+...+\log p(x_n|x_{n-1})$$

    这样可以将条件c直接移动到b中去，就可以减少计算代价，称为伪似然。

    对于完全联合分布模型的任务，伪似然通常效果不好，但对于只使用条件分布的任务，伪似然的效果比最大似然好。

1. 得分匹配和比率匹配

    得分匹配，不需要计算Z，使用对数密度关于参数的导数$\nabla_x \log p(x)$,称为得分。

    得分匹配采用的策略是，最小化模型对数密度和数据对数密度关于输入的导数之间的平方差期望。

    $$L(x,\theta)=\frac {1}{2}||\nabla_x \log p_{model}(x;\theta)-\nabla_x\log p_{data}(x)||_2^2$$

    这个函数避免了微分Z的问题，但引入了需要知道训练数据$p_{data}$的真实分布。不过最小化上式等价于最小化下式：

    $$\hat L(x,\theta)=\sum_{j=1}^n(\frac {\partial^2}{\partial x_j^2}\log p_{model}(x;\theta)+\frac 12(\frac {\partial}{\partial x_j}\log p_{model}(x;\theta))^2)$$

    其中n是x的维度。

    得分匹配涉及到x的导数，所以不适合离散数据的模型。

    一种将得分匹配扩展到离散数据上的方法是比率匹配。比率匹配最小化公司如下：

    $$L^{RM}(x,\theta)=\sum_{j=1}^n(\frac {1}{1+\frac {p_{model(x;\theta)}}{p_{model}(f(x),j;\theta)}})^2$$

    其中 $f(x,j)$ 返回 j 处位值取反的x。

    比率匹配特别适用于二值数据。

    比率匹配可以作为处理高维稀疏数据的基础。

1. 去噪得分匹配

    有时候，拟合以下这样的分布：

    $$P_{smoothed}(x)=\int P_{data}(y)q(x|y)dy$$

    其中q(x|y)是一个损坏过程，也就是在形成x的时候引入少量噪声。

    这样在无法获得$P_{data}$的时候，可以防止形成以训练数据为中心的狄拉克分布。

1. 噪声对比估计

    噪声对比估计（NCE）的概率模型表示为：

    $$\log p_{model}=\log \hat p_(model)(x;\theta)+c$$

    其中 c 是 $-\log Z(\theta)$ 的近似。噪声对比估计将c视为另一参数，使用相同的算法同时计算 $\theta$ 和 c。 最初分布会不一致，但随着 c 估计的改进，会越来越逼近有效值。

    NCE将估计p(x)概率的无监督学习问题转化为学习一个概率的二元分类器，其中一个类别对应模型生成的数据。

    从训练数据上构造一个联合模型，开关变量决定是从数据还是噪声分布中抽取x。然后应用标准最大似然拟合出y=1的$p_{model}$

1. 估计配分函数

    假设有两个模型$M_A$和$A_B$,其概率分布函数分别为：

    $$p_A(x;\theta_A)=\frac 1{Z_A}\hat p_A(x;\theta_A)$$

    $$p_B(x;\theta_A)=\frac 1{Z_B}\hat p_B(x;\theta_B)$$

    比较模型的好坏，通常用相同的测试数据，来评估模型的似然。如果定义测试集为$\{x_1,...x_m\}$，如果：

    $$\sum_i log p_A(x_i;\theta_A)-\sum_i log p_B(x_i;\theta_B)>0$$

    我们可以说模型 $M_A$ 比 $M_B$ 好。

    但上述模型需要知道配分函数，当不知道时采样如下办法：

    $$\sum_i log p_A(x_i;\theta_A)-\sum_i log p_B(x_i;\theta_B)=\sum_i(log\frac {\hat p_A(x_i;\theta_A)}{\hat p_B(x_i;\theta_B)})-mlog\frac {Z(\theta_A)}{Z(\theta_B)}$$

    接下来，采样蒙特卡罗简单重要采样来计算：

    已知： 两个配分函数的比为： $r=\frac {Z(\theta_A)}{Z(\theta_B)}$ 并且知道其中例如 $Z(\theta_A)$ 的实际值，则计算出：

    $$Z(\theta_B)=rZ(\theta_A)=\frac {Z(\theta_B)}{Z(\theta_A)}Z(\theta_A)$$

    然后，利用重要采样，用提议分布 $p_0(x)=\frac 1{Z_0}\hat p_0(x)$ 在配分函数 $Z_0$和未归一化分布 $\hat p_0(x)$ 上采用和估计。

    然后从 $p_0(x)$ 中抽取的采样计算积分 $\hat Z_1$ :

    $$\hat Z_1=\frac {Z_0}{K}\sum _{k=1}^k \frac {\hat p_1(x_k)}{\hat p_0(x_k)}$$

    然后用未归一化的 $\hat p_1$ 和 提议分布的 $p_0$ 的比率对每个采用加权。

    这样就可以估算出配分函数之间的比率：

    $$\frac 1K \sum _{k=1}^k \frac {\hat p_1(x_k)}{\hat p_0(x_k)}$$

    这样就可以将比率带入最初表达式来计算和比较了。

1. 退火重要采样

    当 已知配分函数$P_0$ 与 分布$P_1$ 的KL散度很大的情况下，即没有什么重叠时，可以考虑通过引入中间分布来缩小这种差距，称为退火重要采样（AIS）。

    这种方法可以估计多峰分布。通过对估计模型的配分函数之间的比率得到重要性权重，然后利用马尔可夫链转移函数来转移条件概率分布，最终得到目标的分布采样。

    目前是估计无向模型配分函数的最常用方法。

1. 桥式采样

    退火重要采样是用一系列的中间分布连接在一起，桥式采样只是依赖一个中间分布,在已知配分函数和分布之间插值。

1. 链接重要采样

    如果散度不太大，桥式采样比退火重要采样更高效，如果两个分布太远，则难以使用桥接差距，那么退火重要采样至少可以用多个潜在中间分布来跨越差距。这一种是利用桥式采样的优点，通过桥接AIS使用的中间分布，可以显著的改进整个配分函数的估计。

1. 在训练期间估计配分函数

    使用桥式采样、断链AIS和并行回火的组合，在每一次迭代学习时估计配分函数且保持配分函数方差最小的方法。
    
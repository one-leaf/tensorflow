一般概率模型都是由一个未归一化的概率分布 $\hat p(x,\theta)$ 定义，我们需要除以配分函数$Z(\theta)$ 来归一化$\hat p$，以获得一个有效的概率分布。

配分函数是未归一化概率所有状态的积分（连续变量）或求和（离散变量）。对于很多模型，以上积分或求和都难以计算。

1. 对数似然梯度

    通过最大似然学习无向模型特别困难的原因在于配分函数依赖于参数。对数似然相对于参数的梯度，具有一项对应于配分函数的梯度：

    $$\nabla_\theta \log p(x;\theta)=\nabla_\theta \log \hat p(x;\theta) - \nabla_\theta \log Z(\theta) $$

    这是机器学习中的非常著名的正相和负相的分解。一般正相好计算，但负相的计算比较困难，分析如下：

    $$\nabla_\theta \log Z=\frac {\nabla_\theta Z}{Z}=\frac {\nabla_\theta \sum_x \hat p (x)}{Z}=\frac {\sum_x \nabla_\theta \hat p (x)}{Z}$$

    为了保证所有的p(x)>0，用指数代替:$\hat p(x)=exp (\log \hat p(x))$

    $$\frac {\sum_x \nabla_\theta \hat p (x)}{Z}=\frac {\sum_x \nabla_\theta exp (\log \hat p(x))}{Z}$$

    $$=\frac {\sum_x  exp (\log \hat p(x)) \nabla_\theta \log \hat p(x)}{Z}$$

    $$=\frac {\sum_x  \hat p(x) \nabla_\theta \log \hat p(x)}{Z}$$

    $$=\sum_x  p(x) \nabla_\theta \log \hat p(x)$$

    $$=\mathbb E _{x \sim p(x)}  \nabla_\theta \log \hat p(x)$$

    上面是用离散变量的推导，用连续变量也可以推导出同样的结果：

    $$\nabla_\theta \log Z=\mathbb E _{x \sim p(x)}  \nabla_\theta \log \hat p(x)$$

    这个等式是各种蒙特卡罗方法近似最大化似然的基础。在正相中，增大从数据中采样获得 $\log \hat p(x)$ ， 在负相中通过降低从模型分布中采样的 $\log \hat p(x)$ 来降低配分函数。

    这个就意味着，当数据分布和模型分布相等时，正相推高数据点和负相压低数据点的机会相等，此时，不再有任何期望上的梯度，训练也停止。

1. 随机最大似然和对比散度

    


    
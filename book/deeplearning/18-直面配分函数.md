一般概率模型都是由一个未归一化的概率分布 $\hat p(x,\theta)$ 定义，我们需要除以配分函数$Z(\theta)$ 来归一化$\hat p$，以获得一个有效的概率分布。

$$p(x;\theta)=\frac {1}{Z(\theta)}\hat p(x;\theta)$$

配分函数是未归一化概率所有状态的积分（连续变量）或求和（离散变量）。

$$Z=\int \hat p(x)dx$$

或

$$Z=\sum \hat p(x)$$


对于很多模型，以上积分或求和都难以计算。

1. 对数似然梯度

    通过最大似然学习无向模型特别困难的原因在于配分函数依赖于参数。对数似然相对于参数的梯度，具有一项对应于配分函数的梯度：

    $$\nabla_\theta \log p(x;\theta)=\nabla_\theta \log \hat p(x;\theta) - \nabla_\theta \log Z(\theta) $$

    这是机器学习中的非常著名的正相和负相的分解。一般正相好计算，但负相的计算比较困难，分析如下：

    $$\nabla_\theta \log Z=\frac {\nabla_\theta Z}{Z}=\frac {\nabla_\theta \sum_x \hat p (x)}{Z}=\frac {\sum_x \nabla_\theta \hat p (x)}{Z}$$

    为了保证所有的p(x)>0，用指数代替:$\hat p(x)=exp (\log \hat p(x))$

    $$\frac {\sum_x \nabla_\theta \hat p (x)}{Z}=\frac {\sum_x \nabla_\theta exp (\log \hat p(x))}{Z}$$

    $$=\frac {\sum_x  exp (\log \hat p(x)) \nabla_\theta \log \hat p(x)}{Z}$$

    $$=\frac {\sum_x  \hat p(x) \nabla_\theta \log \hat p(x)}{Z}$$

    $$=\sum_x  p(x) \nabla_\theta \log \hat p(x)$$

    $$=\mathbb E _{x \sim p(x)}  \nabla_\theta \log \hat p(x)$$

    上面是用离散变量的推导，用连续变量也可以推导出同样的结果：

    $$\nabla_\theta \log Z=\mathbb E _{x \sim p(x)}  \nabla_\theta \log \hat p(x)$$

    这个等式是各种蒙特卡罗方法近似最大化似然的基础。在正相中，增大从数据中采样获得 $\log \hat p(x)$ ， 在负相中通过降低从模型分布中采样的 $\log \hat p(x)$ 来降低配分函数。

    这个就意味着，当数据分布和模型分布相等时，正相推高数据点和负相压低数据点的机会相等，此时，不再有任何期望上的梯度，训练也停止。

1. 随机最大似然和对比散度

    对于 $\nabla_\theta \log Z$ 等式有个朴素的解决方案是，每次需要计算梯度时，磨合随机初始化的一组马尔可夫链。当使用随机梯度下降进行学习时，需要每次梯度中计算马尔可夫链，这样计算的代价太大，虽然在实际中是不可行的，但这个过程是其他近似算法的基础。

    我们可以将最大似然的的MCMC方法，看作两种力的平衡，一种是拉高数据出现的模型分布，一种是拉低模型采样出现的模型分布。这两种力分别对应$\log \hat p$和$\log Z$。

    因为负相涉及从模型分布中抽样，所以可以认为它在找模型中信任度很高的点。因为负相减少了这些点的概率，它们一般认为被代表了模型不正确的信念，在文献中通常称为“幻觉”或“幻想粒子”，实际上负相也被作为人类做梦的可能解释。意思是，醒时大脑会遵循$\log \hat p$的梯度，而睡觉时会遵循$\log \hat p$的负梯度最小化$\log Z$。

    一种代价比较低的优化过程：

    >  while 不收敛 do 
    >
    >>  从训练集中采样包含 m 个样本 ${x_1,...,x_m}$ 的小批量
    >
    >>  $g \leftarrow \frac{1}{m} \sum _{i=1}^m \nabla_\theta \log \hat p(x_i;\theta)$ //计算梯度
    >
    >>  for i = 1 to m do
    >>
    >>>  $\hat x_i \leftarrow x_i$ //归一化数据，如果不做方差会偏大，导致训练困难
    >>>
    >> end for
    >
    >> for i = 1 to k do
    >>
    >>> for j = 1 to m do
    >>>
    >>>> $\hat x_j \leftarrow gibbs\_update(\hat x_j)$  //gibbs 采样
    >>>
    >>> end for
    >>>
    >> end for
    >
    >> $g \leftarrow g - \frac{1}{m} \sum _{i=1}^m \nabla_\theta \log \hat p(\hat x_i;\theta)$ //重新计算梯度
    >>
    >> $\theta \leftarrow \theta + \epsilon g$ //更新参数
    >
    > end while

    进行 k 个Gibbs步骤的CD-k算法，在每一步骤中都重新初始化马尔可夫链，这样的计算代价比较小。最初数据的分布和模型分布并不一致，所以负相是不准确的，但正相可以增加数据的模型概率，运行一段时间后，模型会接近数据分布，并且负相也会准确。

1. 伪似然

    因为无向模型很容易计算概率的比率则不需要处理配分函数，这是，配分函数同时在分子和分母，互相抵消了：

    $$\frac {p(x)}{p(y)}=\frac {\frac {1}{Z}\hat p(x)}{\frac {1}{Z}\hat p(y)}=\frac {\hat p(x)}{\hat p(y)}$$

    伪似然正是基于条件概率，可以采样这种基于比率的形式，因此可以不用计算配分函数。

    $$p(a|b)=\frac {p(a,b)}{p(b)}=\frac {p(a,b)}{\sum _{a,c}p(a,b,c)}=\frac {\hat p(a,b)}{\sum _{a,c}\hat p(a,b,c)}$$

    困难在于为了计算对数似然，需要计算边缘概率，利用概率的链式法则展开：

    $$\log p(x)=\log p(x_1)+\log p(x_2|x_1)+...+\log p(x_n|x_{n-1})$$

    这样可以将条件c直接移动到b中去，就可以减少计算代价，称为伪似然。



    